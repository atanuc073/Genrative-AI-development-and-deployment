{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzIrdkBQQbBj"
      },
      "source": [
        "# INSTRUCTION FINE-TUNING"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "RUPuuAXIQnr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
        "            GELU(), ## Activation\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "k8mXRDEzQuHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        # 2*4*768\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "        # 2*4*768"
      ],
      "metadata": {
        "id": "J_VlL-KSQxbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "Ab-0bUzuQyHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "YJLnT3UZQztH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "id": "Ejh6XsevQ1Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "    ###Input batch:\n",
        " ###tensor([[6109, 3626, 6100,  345],\n",
        "        ##[6109, 1110, 6622,  257]])\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "oOSGzYOvQ3JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "\n",
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mWsicqgQ6La",
        "outputId": "22d153f5-35d6-43b3-b96d-06bce518eef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "gvLTDu-wQ7gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "jnGyx-RZSipc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c2pln8KQbBj"
      },
      "source": [
        "## STEP 1: PREPARING DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5ZdpdpEQbBj"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "In this section, we download and format the instruction dataset for instruction finetuning a\n",
        "pretrained LLM in this chapter. The dataset consists of 1100 instruction-response pairs.\n",
        "\n",
        "The following code implements and executes a function to download this dataset, which\n",
        "is a relatively small file, only 204 KB in size, in JSON format. JSON, or JavaScript Object\n",
        "Notation, mirrors the structure of Python dictionaries, providing a simple structure for data\n",
        "interchange that is both human-readable and machine-friendly.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqXKYNF1QbBj",
        "outputId": "6e771427-d248-4087-a676-cab6e38f6ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "import ssl\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "    ssl_context = ssl.create_default_context()\n",
        "    ssl_context.check_hostname = False\n",
        "    ssl_context.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKgaAOXBQbBj"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "The data list , which we loaded from the JSON file contains the 1100 entries of the\n",
        "instruction dataset.\n",
        "\n",
        "Let's print one of the entries to see how each entry is structured:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VTXdoKBQbBj",
        "outputId": "2fe1f2bf-8754-49e7-b76c-727262a018af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYRu4igdQbBj",
        "outputId": "a620559a-c051-4fa6-81ef-6a4c7942239d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Another example entry:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Another example entry:\\n\", data[999])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHE7iP7kQbBj"
      },
      "source": [
        "### CONVERTING INSTRUCTIONS INTO ALPACA FORMAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PiSeQwvQbBj"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hR02iV4QbBj"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "This format_input function takes a dictionary entry as input and constructs a formatted\n",
        "string.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDnyaMwLQbBj"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        " Let's test it to dataset entry data[50], which to looked at earlier:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOvMPrFGQbBj",
        "outputId": "69f7b4ba-ae3e-4f26-a25b-ceb5ce65bc5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIpWQ5IZQbBj"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Note that the format_input skips the optional ### Input: section if the 'input' field is\n",
        "empty, which we can test out by applying the format_input function to entry data[999]\n",
        "that we inspected earlier:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Wfnc9OoQbBj",
        "outputId": "44f19c49-497c-4484-b61b-9faa8941c4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdaXwGZdQbBj"
      },
      "source": [
        "### SPLITTING DATASET INTO TRAIN-TEST-VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j7GsSRoQbBj"
      },
      "outputs": [],
      "source": [
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCXsYvjSQbBk",
        "outputId": "878d758b-d3a4-4af8-e593-82dac5645297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdDEWipCQbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Having successfully downloaded and partitioned the dataset, and gained a clear\n",
        "understanding of the dataset prompt formatting, we are now ready for the core\n",
        "implementation of the instruction finetuning process.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhRKunSoQbBk"
      },
      "source": [
        "## STEP 2: ORGANIZING DATA INTO TRAINING BATCHES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo26_WRvQbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "In the previous chapter, the training batches were created automatically by the PyTorch\n",
        "DataLoader class, which employs a default collate function to combine lists of samples into\n",
        "batches.\n",
        "\n",
        "A collate function is responsible for taking a list of individual data samples and\n",
        "merging them into a single batch that can be processed efficiently by the model during\n",
        "training.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBneOQwLQbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "However, the batching process for instruction finetuning in this chapter is a bit more\n",
        "involved and requires us to create our own custom collate function that we will later plug\n",
        "into the DataLoader.\n",
        "\n",
        "We implement this custom collate function to handle the specific\n",
        "requirements and formatting of our instruction finetuning dataset.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQaYq7QWQbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "First, we code an\n",
        "InstructionDataset class that applies format_input from the previous section and pretokenizes all inputs in the dataset, similar to the SpamDataset in chapter 6.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQSnD2SGQbBk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJT9vgc4QbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Similar to the approach in chapter 6, we aim to accelerate training by collecting multiple\n",
        "training examples in a batch, which necessitates padding all inputs to a similar length.\n",
        "\n",
        "As with the previous chapter, we use the <|endoftext|> token as a padding token.\n",
        "    \n",
        "Instead of appending the <|endoftext|> tokens to the text inputs, we can append its\n",
        "token ID to the pre-tokenized inputs directly.\n",
        "\n",
        "To remind us which token ID we should use,\n",
        "we can use the tokenizer's .encode method on an <|endoftext|> token:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLHle1DKQbBk",
        "outputId": "8afad45f-b22f-43c9-983a-3b27321b49d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHukidw5QbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "In chapter 6, we padded all examples in a dataset to the same length.\n",
        "\n",
        "Moving on, here, we adopt a more sophisticated approach by developing a custom\n",
        "collate function that we can pass to the data loader.\n",
        "\n",
        "This custom collate function pads the\n",
        "training examples in each batch to have the same length, while allowing different batches\n",
        "to have different lengths.\n",
        "\n",
        "This approach minimizes unnecessary\n",
        "padding by only extending sequences to match the longest one in each batch, not the\n",
        "whole dataset.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI_wquhDQbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "We can implement the padding process with a custom collate\n",
        "function as follows:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhyZ9ZCtQbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Step 1: Find the longest sequence in the batch\n",
        "    \n",
        "Step 2: Pad and prepare inputs\n",
        "    \n",
        "Step 3: Remove extra padded token added earlier\n",
        "\n",
        "Step 4: Convert list of inputs to tensor and transfer to target device\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHhbniw2QbBk"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    # and increase the max length by +1, which will add one extra\n",
        "    # padding token below\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to batch_max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        # Via padded[:-1], we remove the extra padded token\n",
        "        # that has been added via the +1 setting in batch_max_length\n",
        "        # (the extra padding token will be relevant in later codes)\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFY3bjXdQbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "The custom_collate_draft_1 we implemented is designed to be integrated into a PyTorch\n",
        "DataLoader, but it can also function as a standalone tool.\n",
        "\n",
        "Here, we use it independently to\n",
        "test and verify that it operates as intended.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4GlIAmeQbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's try it on three different inputs that we\n",
        "want to assemble into a batch, where each example gets padded to the same length:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z777pP42QbBk",
        "outputId": "25f19555-092d-4426-cca0-af4fdb8a8acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuCI9eKLQbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "As we can see based on the preceding output, all inputs have been padded to the length of\n",
        "the longest input list, inputs_1 containing 5 token IDs.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_uTdesKQbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "So far, we have just implemented our first custom collate function to create batches from\n",
        "lists of inputs.\n",
        "\n",
        "However, as you learned in previous lessons, we also need to create batches\n",
        "with the target token IDs, corresponding to the batch of input IDs.\n",
        "\n",
        "These target IDs are crucial because they represent what we want the model to\n",
        "generate and what we need during training to calculate the loss for the weight updates,\n",
        "similar to previous chapters.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eshcwdfRQbBk"
      },
      "source": [
        "#### CREATING TARGET TOKEN IDS FOR TRAINING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NueZ4Ht5QbBk"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Similar to the process described for pretraining an LLM, the target token IDs\n",
        "match the input token IDs but are shifted one position to the right.\n",
        "\n",
        "This setup allows the LLM to learn how to predict the next token in a sequence.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r82sMBwZQbBl"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "The following updated collate function generates the target token IDs from the input token IDs:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxgJ0hD9QbBl"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-INJpoELQbBl"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Step 1: Truncate the last token for inputs\n",
        "                               \n",
        "Step 2: Shift +1 to the right for targets\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxxpEO-LQbBl",
        "outputId": "827d9398-0cc5-42fd-a95e-9d8ddc2970a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOjqNWO2QbBl"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "The 1st tensor represents inputs.\n",
        "    \n",
        "The 2nd tensor represents the targets\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqdVTRBGQbBl"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "In the next step, we assign a -100 placeholder value to all padding tokens.\n",
        "\n",
        "This special value allows us to exclude these padding tokens from contributing to\n",
        "the training loss calculation, ensuring that only meaningful data influences model learning.\n",
        "\n",
        "In classification fine-tuning, we did not have to worry about this since we only trained the model based on\n",
        "the last output token.)\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uct13dYbQbBl"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Note that we retain one end-of-text token, ID 50256, in the target list.\n",
        "\n",
        "This allows the LLM to learn when to generate an end-of-text token\n",
        "in response to instructions, which we use as an indicator that the generated response is\n",
        "complete.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gx6P4dTQbBl"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "In the following code, we modify our custom collate function to replace tokens with ID\n",
        "50256 with -100 in the target lists.\n",
        "\n",
        "Additionally, we introduce\n",
        "an allowed_max_length parameter to optionally limit the length of the samples.\n",
        "\n",
        "This\n",
        "adjustment will be useful if you plan to work with your own datasets that exceed the 1024-\n",
        "token context size supported by the GPT-2 model.\n",
        "\n",
        "The code for this updated collate function\n",
        "is as follows:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ausAkwmtQbBl"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMo2N4ubQbBl"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Step 1: Replace all but the first padding tokens in targets by ignore_index\n",
        "\n",
        "Step 2: Optionally truncate to maximum sequence length\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDis_lc7QbBl"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Again, let's try the collate function on the sample batch that we created earlier to check\n",
        "that it works as intended:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-7yWMLwQbBl",
        "outputId": "9078ce7e-5e5a-4138-cd46-efc718fc5434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3h381RLQbBm"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "In this chapter, we take advantage of this ignore_index to ignore the additional end-oftext (padding) tokens that we used to pad the training examples to have the same length in\n",
        "each batch.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cogYcvyQQbBm"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "However, we want to keep one 50256 (end-of-text)\n",
        "token ID in the targets because it helps the LLM to learn to generate end-of-text tokens,\n",
        "which we can use as an indicator that a response is complete.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9x0saxWQbBm"
      },
      "source": [
        "## STEP 3: CREATING DATALOADERS FOR AN INSTRUCTION DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0enNm9f3QbBm"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The custom_collate_fn includes code to move the input and target tensors (for\n",
        "example, torch.stack(inputs_lst).to(device)) to a specified device, which can be\n",
        "either \"cpu\" or \"cuda\" (for GPUs), or optionally \"mps\" for Macs with Apple Silicon chips.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGb1kS6tQbBm"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "In previous chapters, we moved the data onto the target device (for example, the GPU\n",
        "memory when device=\"cuda\") in the main training loop. Having this as part of the collate\n",
        "function offers the advantage of performing this device transfer process as a background\n",
        "process outside the training loop, preventing it from blocking the GPU during model\n",
        "training.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaSWSotLQbBm"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "The following code initializes the device variable:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1ghrbIZQbBm",
        "outputId": "192e985a-8401-4aab-9a88-01fc4246bdb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# However, the resulting loss values may be slightly different.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qs68-IDQbBm"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, to reuse the chosen device setting in custom_collate_fn when we plug it into the\n",
        "PyTorch DataLoader class later in this section, we use the partial function from Python's\n",
        "functools standard library to create a new version of the function with the device\n",
        "argument pre-filled.\n",
        "\n",
        "Additionally, we set the allowed_max_length to 1024, which truncates\n",
        "the data to the maximum context length supported by the GPT-2 model we finetune later in\n",
        "this chapter:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfePT7CuQbBm"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpLsTKiIQbBm"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, we can set up the data loaders as we did in previous chapters, but this time we will\n",
        "use our custom collate function for the batching process:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTTKwf7wQbBm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxT_J5PiQbBm"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's examine the dimensions of the input and target batches generated by the training\n",
        "loader:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbqzIzGrQbBm",
        "outputId": "918dbd88-8c07-4852-c623-453b9b6beeac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQMYK9eOQbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "In the preceding output, we can see that the first input and target batch have dimensions\n",
        "861, where 8 represents the batch size, and 61 is the number of tokens in each training\n",
        "example in this batch.\n",
        "\n",
        "The second input and target batch have a different number of\n",
        "tokens, for instance, 76.\n",
        "\n",
        "\n",
        "As we saw in the preceding code output, thanks to our custom collate function, the data\n",
        "loader is able to create batches of different lengths.\n",
        "\n",
        "In the next section, we load a\n",
        "pretrained LLM that we can then finetune with this data loader.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YieRBC83QbBn"
      },
      "source": [
        "## STEP 4: LOADING A PRETRAINED LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUPp4T3cQbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Before beginning instruction finetuning, we first load a pretrained GPT model,\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qzGXiSOQbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Instead of using the smallest 124 million\n",
        "parameter model as before, we load the medium-sized model with 355 million parameters.\n",
        "\n",
        "The reason for this choice is that the 124 million parameter model is too limited in capacity\n",
        "to achieve qualitatively satisfactory results via instruction finetuning.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIIeSxHTQbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "This is done using the same code as in section 5.5 of chapter 5 and section 6.4 of\n",
        "the previous chapter, except that we now specify \"gpt2-medium (355M)\" instead of \"gpt2-small\n",
        "(124M)\".\n",
        "\n",
        "Please note that executing the code provided below will initiate the download of\n",
        "the medium-sized GPT model, which has a storage requirement of approximately 1.42\n",
        "gigabytes.\n",
        "\n",
        "This is roughly three times larger than the storage space needed for the small\n",
        "model:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gWFrQApQbBn",
        "outputId": "7a79bba2-5a46-41f1-90a6-da0f462dc56d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "checkpoint: 100%|| 77.0/77.0 [00:00<00:00, 152kiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "encoder.json: 100%|| 1.04M/1.04M [00:00<00:00, 2.19MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "hparams.json: 100%|| 91.0/91.0 [00:00<00:00, 217kiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.data-00000-of-00001: 100%|| 1.42G/1.42G [01:37<00:00, 14.6MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.index: 100%|| 10.4k/10.4k [00:00<00:00, 19.4MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.meta: 100%|| 927k/927k [00:00<00:00, 2.72MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "vocab.bpe: 100%|| 456k/456k [00:00<00:00, 2.01MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from gpt_download3 import download_and_load_gpt2\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvTgLjF5QbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Before diving into finetuning the model in the next section, let's take a moment to assess\n",
        "the pretrained LLM's performance on one of the validation tasks by comparing its output to\n",
        "the expected response.\n",
        "\n",
        "This will give us a baseline understanding of how well the model\n",
        "performs on an instruction-following task right out of the box, prior to finetuning, and will\n",
        "help us appreciate the impact of finetuning later on.\n",
        "\n",
        "We use the first example from the\n",
        "validation set for this assessment:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu0mry0rQbBn",
        "outputId": "e8cffc6d-29b5-4d24-f1bb-cef364f84e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSiOo6mbQbBn"
      },
      "outputs": [],
      "source": [
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVb-HGrGSPFR",
        "outputId": "cc8bdf81-b7e5-4856-8b0b-af6bc319eddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaBv4Wp9QbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "It's important to note that the generate function returns the combined input and output\n",
        "text.\n",
        "\n",
        "This behavior was convenient in previous chapters since pretrained LLMs are primarily\n",
        "designed as text-completion models, where the input and output are concatenated to\n",
        "create a coherent and legible text.\n",
        "\n",
        "However, when evaluating the model's performance on a\n",
        "specific task, we often want to focus solely on the model's generated response.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0hLBEE7QbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "To isolate the model's response text, we need to subtract the length of the input\n",
        "instruction from the start of the generated_text:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsnaLTTlQbBn",
        "outputId": "2fe9cee8-957e-4163-f8ff-d14d2df70714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "response_text = generated_text[len(input_text):].strip()\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHaF7twRQbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "This code snippet removes the input text from the beginning of the generated_text,\n",
        "leaving us with only the model's generated response. The strip() function is then applied\n",
        "to remove any leading or trailing whitespace characters. The output is as follows:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W_LBLFqQbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "As we can see from the output, the pretrained model is not yet capable of correctly\n",
        "following the given instruction.\n",
        "\n",
        "While it does create a \"Response\" section, it simply repeats\n",
        "the original input sentence and part of the instruction, failing to convert the active sentence\n",
        "to passive voice as requested.\n",
        "\n",
        "\n",
        "In the upcoming section, we implement the finetuning process to improve the model's\n",
        "ability to comprehend and appropriately respond to such requests.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDbxx_8NQbBn"
      },
      "source": [
        "## STEP 5: FINETUNING THE LLM ON INSTRUCTION DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnUnztt2QbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "We already did all the hard work when we implemented the\n",
        "instruction dataset processing at the beginning of this chapter.\n",
        "\n",
        "For the finetuning process\n",
        "itself, we can reuse the loss calculation and training functions implemented in chapter 5\n",
        "during the pretraining:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFU2NC9PQbBn"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Before we begin training, let's calculate the initial loss for the training and validation sets:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "368zqQ_iQbBn"
      },
      "source": [
        "#### PREVIOUSLY DEFINED FUNCTIONS WHICH WE WILL REQUIRE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBzaLVOKQbBn"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gDeZrarQbBo",
        "outputId": "52c93e31-68b6-478c-e41c-dbdf89af50b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.825909376144409\n",
            "Validation loss: 3.7619347095489504\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRqGcMJXQbBo"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "With the model and data loaders prepared, we can now proceed to train the model.\n",
        "\n",
        "The following code sets up the training process, including initializing the optimizer, setting the\n",
        "number of epochs, and defining the evaluation frequency and starting context to evaluate\n",
        "generated LLM responses during training based on the first validation set instruction\n",
        "(val_data[0]) we looked at earlier:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybi8tx1cQbBo",
        "outputId": "03d77246-bfa4-4e17-e673-c4f0b3716e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
            "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
            "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.533, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.568, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.604, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
            "Ep 1 (Step 000090): Train loss 0.563, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.504, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.565, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
            "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.663\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.671\n",
            "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.687\n",
            "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
            "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.682\n",
            "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.681\n",
            "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.681\n",
            "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
            "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.675\n",
            "Ep 2 (Step 000160): Train loss 0.412, Val loss 0.684\n",
            "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
            "Ep 2 (Step 000170): Train loss 0.322, Val loss 0.680\n",
            "Ep 2 (Step 000175): Train loss 0.338, Val loss 0.667\n",
            "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
            "Ep 2 (Step 000185): Train loss 0.414, Val loss 0.657\n",
            "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
            "Ep 2 (Step 000195): Train loss 0.328, Val loss 0.633\n",
            "Ep 2 (Step 000200): Train loss 0.309, Val loss 0.633\n",
            "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.631\n",
            "Ep 2 (Step 000210): Train loss 0.364, Val loss 0.630\n",
            "Ep 2 (Step 000215): Train loss 0.393, Val loss 0.634\n",
            "Ep 2 (Step 000220): Train loss 0.297, Val loss 0.644\n",
            "Ep 2 (Step 000225): Train loss 0.342, Val loss 0.658\n",
            "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.656\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
            "Training completed in 3.25 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy920q3bQbBo"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "\n",
        "As we can see based on the outputs above, the model trains well, as we can tell based on the decreasing training loss and validation loss values.\n",
        "    \n",
        "Furthermore, based on the response text printed after each epoch, we can see that the model almost correctly follows the instruction to convert the input sentence 'The chef cooks the meal every day.' into passive voice 'The meal is prepared every day by the chef.' (We will properly format and evaluate the responses in a later section.\n",
        "\n",
        "To get better results, we need to finetune the model for more epochs.\n",
        "\n",
        "Finally, let's take a look at the training and validation loss curves\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMMyAjD7QbBo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "xH7rSpUXQbBo",
        "outputId": "0d6fc9b3-db2d-4ecd-86a2-1a2c21b9f092"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hBeXC4zQbBo"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "\n",
        "As we can see in the loss plot shown above, the model's performance on both the\n",
        "training and validation sets improves substantially over the course of training.\n",
        "\n",
        "The rapid\n",
        "decrease in losses during the initial phase indicates that the model is quickly learning\n",
        "meaningful patterns and representations from the data. Then, as training progresses to the\n",
        "second epoch, the losses continue to decrease but at a slower rate, suggesting that the\n",
        "model is finetuning its learned representations and converging to a stable solution.\n",
        "\n",
        "\n",
        "While the loss plot in figure 7.17 indicates that the model is training effectively, the most\n",
        "crucial aspect is its performance in terms of response quality and correctness. In the\n",
        "remaining sections of this chapter, we will extract the responses and store them in a format\n",
        "that allows us to evaluate and quantify the response quality.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1yETqdNQbBo"
      },
      "source": [
        "## STEP 6: EXTRACTING AND SAVING RESPONSES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofFNbmM7QbBo"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "After finetuning the LLM on the training portion of the instruction dataset as described in\n",
        "the previous section, we now proceed to evaluate its performance on the held-out test set.\n",
        "    \n",
        "To accomplish this, we first extract the model-generated responses for each input in the\n",
        "test dataset and collect them for manual analysis\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQG5W84SQbBo"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "\n",
        "Step 1: Iterate over the first 3 test set samples\n",
        "\n",
        "Step 2:  Use the generate function defined earlier\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjFfB70uQbBo"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "As mentioned earlier, the generate function returns the combined input and output text, so\n",
        "we use slicing and the .replace() method on the generated_text contents to extract the\n",
        "model's response.\n",
        "\n",
        "The instructions, followed by the given test set response and model\n",
        "response are shown below:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwLEDRjGQbBo",
        "outputId": "d5fd8afd-38ac-4e31-bfff-52eda76a6762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pglTlD9pQbBo"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "\n",
        "As we can see based on the test set instructions, given responses, and the model's\n",
        "responses, the model performs relatively well.\n",
        "\n",
        "The answers to the first instruction\n",
        "is clearly correct, while the second answer and the third answers are not correct.\n",
        "\n",
        "This is because we have done the fine-tuning for only 1 epoch due to hardware limitations. To get better results, we need to increase the epochs to at least 2.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvrJREZdQbBo"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Most importantly, we can see that model evaluation is not as straightforward as in the\n",
        "previous chapter, where we simply calculated the percentage of correct spam/non-spam\n",
        "class labels to obtain the classification accuracy.\n",
        "\n",
        "In practice, instruction-finetuned LLMs\n",
        "such as chatbots are evaluated via multiple approaches:\n",
        "\n",
        "1. Short-answer and multiple choice benchmarks such as MMLU (\"Measuring\n",
        "Massive Multitask Language Understanding,\" https://arxiv.org/abs/2009.\n",
        "03300), which test the general knowledge of a model.\n",
        "\n",
        "2. Human preference comparison to other LLMs, such as LMSYS chatbot\n",
        "arena (https://arena.lmsys.org).\n",
        "\n",
        "3. Automated conversational benchmarks, where another LLM like GPT-4 is\n",
        "used to evaluate the responses, such as AlpacaEval (https://tatsulab.github.io/alpaca_eval/).\n",
        "completes the request.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P17tyKI8QbBo"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Considering the scale of the task at hand, we will implement an approach similar to\n",
        "method 3, which involves evaluating the responses automatically using another LLM.\n",
        "\n",
        "This\n",
        "will allow us to efficiently assess the quality of the generated responses without the need\n",
        "for extensive human involvement, thereby saving time and resources while still obtaining\n",
        "meaningful performance indicators.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znuuwjwoQbBp"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "To prepare the responses for this evaluation process, we append the generated model\n",
        "responses to the test_set dictionary and save the updated data as an \"instructiondata-with-response.json\" file for record keeping.\n",
        "\n",
        "Additionally, by saving this file, we can\n",
        "easily load and analyze the responses in separate Python sessions later on if needed.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVYjESQDQbBp"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "The following code uses the generate method in the same manner as before; however,\n",
        "we now iterate over the entire test_set.\n",
        "\n",
        "Also, instead of printing the model responses, we\n",
        "add them to the test_set dictionary:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwjZUI-kQbBp",
        "outputId": "6859ccf5-0aa7-4b81-ae25-a0505157a100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 110/110 [01:07<00:00,  1.64it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrd65UKWQbBp"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's verify that the responses have been correctly added to the test_set dictionary by\n",
        "examining one of the entries:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT0HuEsVQbBp",
        "outputId": "60dc8346-7a54-4e87-ea61-588123e2a04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ],
      "source": [
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCExAfDLQbBp"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "\n",
        "Based on the output, we can see that the model_response has been added correctly.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "088vhpYzQbBp"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Finally, we save the model as gpt2-medium355M-sft.pth file to be able to reuse it in future\n",
        "projects:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9NBecRnQbBp",
        "outputId": "8f192bad-e879-4a2d-d7ba-e4f0de2a90bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")\n",
        "\n",
        "# Load model via\n",
        "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3bVwuPSQbBp"
      },
      "source": [
        "## STEP 7: EVALUATING THE FINE-TUNED LLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip -q install  accelerate bitsandbytes\n",
        "%pip -q install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB8ZCVtrEoSp",
        "outputId": "07915993-c3b6-40cf-94dd-99ee41afc50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()  # shows a small UI prompt to paste your token securely\n"
      ],
      "metadata": {
        "id": "8VygiVD8HJ-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "d0a583bedb654a82b10505d09c5f3f97",
            "e2deedc72968430aa8f9f74d75673739",
            "9e795ff0fd33427b9e249f684a7d60ca",
            "fa44783995044fbc9e50695e884650d9",
            "e18ca82d2e2c45c48d81e8208a7c4f42",
            "9cff097dfa4b46bd8df0bc7088389e26",
            "7d7c78b582a64b14917fdb792fb8cdc8",
            "23b32bd5d2384300908d5a5d339c150b",
            "21148aae610e4fa0bd6445d1dbe67d8c",
            "f37b3d96718c4261b11e9c9ebc91c35e",
            "f0ce4255e9384614a01d8beacc392c06",
            "264e9f4b2b5948b9af20dd0bced11bb5",
            "12821b4ce74943e6949bf3d362061f08",
            "035ed32af0224b9fb3e72ade7b686ee0",
            "2cb0642e017c4cc5a85fff6e26ae30b5",
            "5383dd5faf774f42ab2b302f3f55c502",
            "21bbca06eb5045dba9919601a84f3eed",
            "c0841771838c4bf997627206c334d9cc",
            "ad7967dfd1c94a1d9e16cf5259668037",
            "5cb460c0a25842e6ab7860717e221c63"
          ]
        },
        "outputId": "402f7a58-3bdf-41b7-91a0-7c3fd581323f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0a583bedb654a82b10505d09c5f3f97"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    set_seed,\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "#  CONFIG (per your request)\n",
        "# ==============================\n",
        "HF_TOKEN = \"\"  # <-- using your key explicitly\n",
        "MODEL_ID = \"google/gemma-7b-it\"\n",
        "USE_4BIT = True  # quantized model\n",
        "DEFAULT_DTYPE = \"bfloat16\"  # set to \"float16\" if your GPU doesn't support bf16\n",
        "\n",
        "# Make the token available to HF clients too\n",
        "#os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
        "#os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = HF_TOKEN\n",
        "\n",
        "# ==============================\n",
        "#  UTILS: dtype + CUDA checks\n",
        "# ==============================\n",
        "def _gpu_supports_bf16() -> bool:\n",
        "    if not torch.cuda.is_available():\n",
        "        return False\n",
        "    major, minor = torch.cuda.get_device_capability()\n",
        "    # Ampere (8.0+) generally supports bf16\n",
        "    return major >= 8\n",
        "\n",
        "def _resolve_dtype(cfg_dtype: str):\n",
        "    if cfg_dtype == \"bfloat16\" and not _gpu_supports_bf16():\n",
        "        return torch.float16\n",
        "    return torch.bfloat16 if cfg_dtype == \"bfloat16\" else torch.float16\n",
        "\n",
        "# ==============================\n",
        "#  LOAD GEMMA-7B-IT (4-bit)\n",
        "# ==============================\n",
        "def load_gemma_it(\n",
        "    model_id: str = MODEL_ID,\n",
        "    use_4bit: bool = USE_4BIT,\n",
        "    dtype: str = DEFAULT_DTYPE\n",
        "):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    if use_4bit:\n",
        "        if device != \"cuda\":\n",
        "            raise RuntimeError(\n",
        "                \"4-bit quantization with bitsandbytes requires a CUDA GPU. \"\n",
        "                \"Enable a GPU runtime or set USE_4BIT=False (not recommended for 7B on CPU).\"\n",
        "            )\n",
        "\n",
        "        compute_dtype = _resolve_dtype(dtype)\n",
        "        quant_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=compute_dtype,\n",
        "        )\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            quantization_config=quant_config,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=compute_dtype,\n",
        "            token=HF_TOKEN,\n",
        "        )\n",
        "    else:\n",
        "        # Non-quantized path (will need lots of VRAM). Kept for completeness.\n",
        "        compute_dtype = _resolve_dtype(dtype)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=compute_dtype,\n",
        "            token=HF_TOKEN,\n",
        "        )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id, token=HF_TOKEN)\n",
        "\n",
        "    # Deterministic generation defaults\n",
        "    set_seed(123)\n",
        "    model.generation_config.seed = 123\n",
        "    model.generation_config.do_sample = False\n",
        "    model.generation_config.temperature = 0.0\n",
        "    model.generation_config.top_p = 1.0\n",
        "    model.generation_config.max_new_tokens = 256\n",
        "    model.generation_config.use_cache = True\n",
        "\n",
        "    return tokenizer, model, device\n",
        "\n",
        "tokenizer, model, device = load_gemma_it()\n",
        "\n",
        "# ==============================\n",
        "#  CHAT / INFERENCE\n",
        "# ==============================\n",
        "def query_model(\n",
        "    prompt: str,\n",
        "    model_name: str = MODEL_ID,\n",
        "    temperature: float = 0.0,\n",
        "    top_p: float = 1.0,\n",
        "    max_new_tokens: int = 256,\n",
        "    seed: int = 123,\n",
        "):\n",
        "    \"\"\"\n",
        "    Instruction-tuned chat for Gemma-7B-IT using the tokenizer's chat template.\n",
        "    Deterministic by default (temperature=0).\n",
        "    \"\"\"\n",
        "    set_seed(seed)\n",
        "    do_sample = (temperature is not None) and (temperature > 0.0)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    chat = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    inputs = tokenizer(chat, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            do_sample=do_sample,\n",
        "            temperature=temperature if do_sample else None,\n",
        "            top_p=top_p if do_sample else None,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    generated = output_ids[0, inputs[\"input_ids\"].shape[1]:]\n",
        "    text = tokenizer.decode(generated, skip_special_tokens=True)\n",
        "    return text.strip()\n",
        "\n",
        "# ==============================\n",
        "#  QUICK TEST\n",
        "# ==============================\n",
        "result = query_model(\"What do llamas eat?\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488,
          "referenced_widgets": [
            "8ca3f7b997234db3a12988b4f6003a06",
            "2147f4d48adc48d1868ace541208119c",
            "7e6ce276f8b94d1d91094af28bc206d1",
            "5079c0596feb4b668d4aff7b16349d0a",
            "60da22588c064c0a8b930ca7c11279f5",
            "eee9c21d9a9d4a1c8ffbb168a9a347e1",
            "fe1fbffc25f849e5935b650606110e8f",
            "f36f61d7ac474546ba0da40ec88b3117",
            "bd39412faa96400aa70a50e9643783b2",
            "5062645f605b434ca9407c0661218ca3",
            "aada674efbd64805b68dd7137cbcaa84",
            "9f068319f9b6439e829189cb6582d8b0",
            "f5d1271a0d1d45b89dcf1c968363b626",
            "c933ab7479444033aacad2a2976b18c9",
            "e06aa4757eb64658ab010c28bd11ae2c",
            "d6da6b8669df4453aa45a11daae8a302",
            "631fc20a92c54ad2a0be119346bb9698",
            "e3fe5c62979f46f1a2d0437107918a1b",
            "c175cb302cb941a3a6eef70085dc83ce",
            "801e738577a84b4eaf9d658acb826646",
            "f8de19591f424c1baab9bf8ff06596ab",
            "1015620c16f948d1972d1feaf08f7c2b",
            "c276461a5d09461cb42dbd988c689557",
            "62e5304fcb1d45179384b8d713b5ac28",
            "258a9c77d34c431899f4061b9999f4a2",
            "02e00a7a66494440932a1ccd84db162c",
            "2747481db70c4df0b7cefedcf8b78cac",
            "0437ef801bb4409cace7864a606a0433",
            "ee78d74af7a648bcad02b27bb26984b0",
            "0bb6a0b385fe483badaf0aeb6aa9647b",
            "fba63b261a4049afa864c53b54104c38",
            "72d2a843350847b9b7a20eaa5b56cf20",
            "aaa4f22ad9634d14b3bfaf91649417a9",
            "20bc7d2347c14908b357e1bcee0ffb29",
            "2dae06a15d7c4d47971cf14985ed66cb",
            "2796455526254859ba3927306b0caa01",
            "2c8f07b1c4134e86b63678adf2a75938",
            "f679feab502b4e2bb883ce551acec3c3",
            "c65ad649ce254c0496dc3c607eae01b4",
            "9d4efa3edee748e085dee3bfed48f18c",
            "d752338b47f04722bef97c87de1bb48b",
            "3f23dd9973d94c9a82a949a96cc0d82d",
            "fd44e4924ccf4a2188bad3087d5f4c81",
            "7b25e494998049cd8c5d29a95880a849",
            "c79d2b2cba1c43479ba7949933fd027d",
            "ab6bcd3eafbe46f2b2f9b874c1ed1e2c",
            "59da91f5a0224b84a5669a08fc0a41fe",
            "46f0dc67813848ceb2876b071c2d1ee5",
            "b7f27f8ae0a54239ad992bfe398f753d",
            "f8d35cef0eee4bab988168453dc3af06",
            "9ade9ce2a096413fa12ab402befff7ec",
            "5245b274e7bb46b695c716f6c54f32ed",
            "52879b038558492aaeb1cbb08bc50cca",
            "44c6088f5fd048d289271952ed078809",
            "6aa0af963b1e4a9185d51678463ecf5b",
            "87e18a1cbd46443ea1d0a614a575099d",
            "0850869d952b41b580de763bb9a15970",
            "8a31a2cf0ffa4a80a33cbb5df1a9df9c",
            "fd12a8baab3a49b1a2a91616e169c64c",
            "23e9d9b38e504b399261c14007eee440",
            "f3d797e87290434e83ab592c836a0e77",
            "3f28081bcc524b9ca01f890cc138f0cc",
            "d825e1213ae5408e9c4c64b6d40dde06",
            "2f922c22827c4c9caca54306df1076e9",
            "250acf920eb04782bc09965ab037c97c",
            "f3351dea1cc0450186f32d1a2ee20336",
            "17652f2c5669462594278408281823c3",
            "27c9622af97a450a9a67ae52ebecf641",
            "d7c00740b4544a659b165efe834b7f14",
            "548429346d5645eeb3a1eb9b9340c320",
            "0cc3d3340f8141c7b1a0fd9e4d8d6932",
            "89484001fd4c4baea991e684e7973157",
            "945c0420d870419297edf8846f366bed",
            "f6711053fb6749c1b5a3a3d7a6910a46",
            "02981208401041e4a1798cbd141ecce7",
            "250c85bdd200496c89936192fc310253",
            "9afa0665140d482ba459b83f53294c53",
            "67835dafdafe4f7fabeaaf7bf6d1518b",
            "a6fd276d6c61436682c699d350a39f50",
            "b1d5d16d4dcf48bd8504762fd9b27d88",
            "66884c0006524849824a5ec743043ff4",
            "bdbb6982cf8e4dfc8faa690aa06a06c1",
            "ccf5f6b798e94b02aa306145c2ce3119",
            "bae502726b9c43108317e15c94d5c920",
            "f40acf959a4045d89647f08b7d96471d",
            "03c0698156e146b0b3b750f5e47dc111",
            "282cfadca0fa4715aba0f66dcf7fd6bc",
            "ccfe3c4bd3e74c459137617b3b547855",
            "ee475032449a4268821bcaf4f514b78b",
            "e9af5edc639b431fba201c76f3b7add0",
            "e99ad37eb9074d4584587b99e81e3648",
            "125c603dc6a14d8caf109218091090eb",
            "84e45dd177884294aa988b3e85d0e701",
            "52376e5ea91d448a89a20729d33570ee",
            "84e60fb643d84943a6e40686881292aa",
            "4b68cb5fa608460f8e87946e06f0761a",
            "bfb788b1e6904f268ba161418721f4c4",
            "97217933b7524caf87a6c18a78d1061c",
            "39e82298349c4f9da6280d7131b9886f",
            "d273e8b79cd944ddbd711fc0887d06a4",
            "8ff20f77b95044f1b73e8290affa20ad",
            "d3054d1047804e0581113ba1f94cb5d9",
            "8b785df9835340028a475e75e65792da",
            "199716715ac24d108970f69685aac235",
            "a440ffbbdf0e4765ba9c401269480ca5",
            "391e392bb4bc4449892fe14af1f35d28",
            "a8ee5eae3fc349e5bfcfbed47054db46",
            "a30d0e3d051f4d8492a80572c2af245a",
            "a307dfbe610c44a4a17534fa2aac2eec",
            "8c1513ccdccd4951af6591587c62a787",
            "d2d2675a6ae14583a4992f8e1baf6208",
            "e63fdfcd83a74c4fb9ad5bb210d0730a",
            "35c0732a41084e1dbf150f41fa0219cc",
            "9ecff7822b994d71a71d593d9dc00cde",
            "c313f8cd52e04a5a98810d543766ab17",
            "ef7c590a53e74e809cf9dc787c559eed",
            "7206b40a063b466e940295b737b71308",
            "e799b091fa114f56a806c374fc0ed7f4",
            "cac327851013466d945cfc76e81e7474",
            "de357e6f633d4e8786ef38d9e379e03b",
            "be6d5ff8b4ac4f489d40bd7f2751d575",
            "cafcb2a0baac4c44bee93512bb2f7fcb",
            "43455d9082e14674a552337da30b48a1",
            "8b55f733e19d446a88ae501d81212aef",
            "440c067c133a4223a8143b73b8562359",
            "ebf1a83e56e5464291d4a3bb85602fa5",
            "5aec701d64bc422f9f0a6a7fdcbb6134",
            "39df6952cf344db5af55adc26470a10b",
            "9952e2fae8e14de8bb3b8e0abf9ca63f",
            "e9cf7da03d2a4bc3a97b98021c7da8fb",
            "2b3e109185ae4f6590dcc2e3db430003",
            "b818aae861794cc2a635efd2e59955d4",
            "0081099aad4e4bbabb316260b6f4aa93",
            "0846147fe114458db6d7b88601de0304",
            "a71c17788c4c4e048b3c2448591c6c35",
            "0eaaa5a6854143e4aae1de9c785950c8",
            "35dc0034b45a4474a27aefa46cc54ee0",
            "f882311eeead4439b55cbe9b0e3cdb6a",
            "17db83cef44142efbcee6d8f310312b0",
            "e9f8ceb2c24441da99116e1d1a12cadf",
            "41bf276faef54df1aea1e29468f52812",
            "50b64e84ac42458ba2de5bbddf76d375",
            "52de5aa88ffa400eb1085184eccd2722"
          ]
        },
        "id": "PGF4lZIlEuCU",
        "outputId": "bd4136a8-6e92-424e-eda5-2c6a92b8d473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ca3f7b997234db3a12988b4f6003a06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f068319f9b6439e829189cb6582d8b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c276461a5d09461cb42dbd988c689557"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/2.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20bc7d2347c14908b357e1bcee0ffb29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c79d2b2cba1c43479ba7949933fd027d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87e18a1cbd46443ea1d0a614a575099d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17652f2c5669462594278408281823c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67835dafdafe4f7fabeaaf7bf6d1518b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee475032449a4268821bcaf4f514b78b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d273e8b79cd944ddbd711fc0887d06a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2d2675a6ae14583a4992f8e1baf6208"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cafcb2a0baac4c44bee93512bb2f7fcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0081099aad4e4bbabb316260b6f4aa93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Llamas are herbivores, which means they eat only plants. Their diet consists mainly of grasses, shrubs, and cacti. Llamas also eat leaves, stems, flowers, and fruits.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #==============================\n",
        "#  EVAL / SCORING HELPERS\n",
        "# ==============================\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Expecting you already define:\n",
        "#   - test_data: list of dicts with keys like 'output', 'model_response', etc.\n",
        "#   - format_input: function to render the input side of each sample.\n",
        "# The loops below mirror your original structure.\n",
        "\n",
        "if \"test_data\" in globals() and \"format_input\" in globals():\n",
        "    subset = test_data[:3] if len(test_data) >= 3 else test_data\n",
        "    for entry in subset:\n",
        "        prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry['model_response']}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "        )\n",
        "        print(\"\\nDataset response:\")\n",
        "        print(\">>\", entry['output'])\n",
        "        print(\"\\nModel response:\")\n",
        "        print(\">>\", entry[\"model_response\"])\n",
        "        print(\"\\nScore:\")\n",
        "        print(\">>\", query_model(prompt))\n",
        "        print(\"\\n-------------------------\")\n",
        "\n",
        "    subset2 = test_data[:2] if len(test_data) >= 2 else test_data\n",
        "    for entry in subset2:\n",
        "        prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry['model_response']}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "        score = query_model(prompt)\n",
        "        print(\"\\nDataset response:\")\n",
        "        print(\">>\", entry['output'])\n",
        "        print(\"\\nModel response:\")\n",
        "        print(\">>\", entry[\"model_response\"])\n",
        "        print(\"\\nScore:\")\n",
        "        print(\">>\", score)\n",
        "        print(\"\\n-------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMtDtUmZFF1t",
        "outputId": "d661647f-8e90-4b94-fc6a-e508ee599a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "Score:\n",
            ">> ## Model Response:\n",
            "\n",
            "The car is as fast as a bullet.\n",
            "\n",
            "**Score:** 90/100\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "The model correctly identified the need to use a simile comparing the car's speed to something extremely fast, like a bullet. The simile \"as fast as a bullet\" is a common and effective way to describe extreme speed. The use of the word \"bullet\" is also appropriate in this context, as it is a powerful and evocative image that evokes speed and velocity.\n",
            "\n",
            "**Areas for Improvement:**\n",
            "\n",
            "* The model could have used a more precise simile that more accurately reflects the speed of the car.\n",
            "* The model could have used a more creative simile that is unique and memorable.\n",
            "\n",
            "**Overall:**\n",
            "\n",
            "This is a well-written response that appropriately completes the request. The model has a strong understanding of the task and is able to produce a high-quality response.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "\n",
            "Score:\n",
            ">> ## Model Response:\n",
            "\n",
            "The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "**Score:** 90/100\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "The instruction clearly states that the task is to identify the type of cloud associated with thunderstorms. Cumulonimbus clouds are the type of cloud that are most commonly associated with thunderstorms. Therefore, the model's response is highly accurate and appropriately completes the request.\n",
            "\n",
            "**Areas for Improvement:**\n",
            "\n",
            "* The model could provide a more detailed explanation of why cumulonimbus clouds are associated with thunderstorms.\n",
            "* The model could cite sources or references to support the information provided.\n",
            "\n",
            "**Overall:**\n",
            "\n",
            "This model response is well-written and demonstrates a good understanding of the task. It accurately identifies the type of cloud associated with thunderstorms and provides a concise and clear response.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "\n",
            "Score:\n",
            ">> **Response:**\n",
            "\n",
            "The author of 'Pride and Prejudice' is Jane Austen.\n",
            "\n",
            "**Score:** 100\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "The instruction clearly states the task, which is to name the author of 'Pride and Prejudice'. The response accurately answers the question by stating \"Jane Austen\" as the author, which is the correct answer. The response is concise, direct, and to the point. It also adheres to the requested format of \"The author of 'Pride and Prejudice' is [author's name].\"\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "Score:\n",
            ">> The model response is: 80\n",
            "\n",
            "The sentence: The car is very fast.\n",
            "\n",
            "The rewritten sentence using a simile: The car is as fast as lightning.\n",
            "\n",
            "The rewritten sentence using a simile is well-written and accurately captures the meaning of the original sentence. The simile \"as fast as lightning\" is effective and concise.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "\n",
            "Score:\n",
            ">> The model response is incorrect. The type of cloud typically associated with thunderstorms is cumulonimbus, not cumulus.\n",
            "\n",
            "**Score:** 20/100\n",
            "\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_model_scores(json_data, json_key, model=MODEL_ID):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
        "        prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry[json_key]}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "        score_text = query_model(prompt)\n",
        "        try:\n",
        "            scores.append(int(score_text))\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert score: {score_text}\")\n",
        "            continue\n",
        "    return scores"
      ],
      "metadata": {
        "id": "pDkVI3kpFIoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, csv, math\n",
        "from pathlib import Path\n",
        "from statistics import mean\n",
        "\n",
        "# === Config ===\n",
        "JSON_PATH = \"instruction-data-with-response.json\"   # <-- change if needed\n",
        "JSON_KEY  = \"model_response\"                             # field to score\n",
        "OUT_CSV   = \"gemma_judge_scores.csv\"\n",
        "\n",
        "\n",
        "\n",
        "# --- Load your dataset ---\n",
        "json_path = Path(JSON_PATH)\n",
        "with json_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "# --- Run judge scoring (uses your existing generate_model_scores + query_model) ---\n",
        "scores = generate_model_scores(test_data, JSON_KEY)  # <- calls your query_model under the hood\n",
        "\n",
        "# --- Print average score ---\n",
        "avg = mean(scores) if scores else float(\"nan\")\n",
        "print(f\"\\nScored {len(scores)} items.\")\n",
        "print(f\"Average score: {avg:.2f}\\n\")\n",
        "\n",
        "# --- Save per-item scores to CSV ---\n",
        "with open(OUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"idx\", \"score_0_100\", \"instruction\", \"input\"])\n",
        "    for i, (entry, s) in enumerate(zip(test_data, scores)):\n",
        "        writer.writerow([\n",
        "            i,\n",
        "            s,\n",
        "            (entry.get(\"instruction\") or \"\").replace(\"\\n\", \" \").strip(),\n",
        "            (entry.get(\"input\") or \"\").replace(\"\\n\", \" \").strip(),\n",
        "        ])\n",
        "\n",
        "print(f\"Saved per-item scores to: {OUT_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh3k-uHzGgXM",
        "outputId": "81aac0da-8eda-4a0c-d2a4-a97407d33f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring entries:   1%|          | 1/110 [00:04<08:42,  4.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is: 80\n",
            "\n",
            "The sentence: The car is very fast.\n",
            "\n",
            "The rewritten sentence using a simile: The car is as fast as lightning.\n",
            "\n",
            "The rewritten sentence using a simile is well-written and accurately captures the meaning of the original sentence. The simile \"as fast as lightning\" is effective and concise.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:   2%|         | 2/110 [00:07<06:16,  3.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is incorrect. The type of cloud typically associated with thunderstorms is cumulonimbus, not cumulus.\n",
            "\n",
            "**Score:** 20/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:   3%|         | 3/110 [00:10<06:10,  3.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "The author of 'Pride and Prejudice' is Jane Austen.\n",
            "\n",
            "**Score:** 100\n",
            "\n",
            "The text accurately identifies the author of 'Pride and Prejudice' as Jane Austen and provides a complete and concise statement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:   4%|         | 4/110 [00:14<06:03,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is incorrect. The periodic symbol for chlorine is Cl, not C.\n",
            "\n",
            "**Score:** 0\n",
            "\n",
            "The model has made a mistake in identifying the periodic symbol for chlorine. The correct answer is Cl, not C.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:   5%|         | 5/110 [00:16<05:20,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Answer:** 100\n",
            "\n",
            "The sentence is already corrected to \"It's time to go home.\". There are no errors in the punctuation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:   5%|         | 6/110 [00:21<06:15,  3.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "The sentence is \"The lecture was delivered in a clear manner.\"\n",
            "\n",
            "The model response is \"The lecture was delivered clearly.\"\n",
            "\n",
            "The response is grammatically correct and accurately rewrites the sentence. It also uses the same wording as the original sentence, which is a good sign of understanding the instruction.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:   6%|         | 7/110 [00:24<06:10,  3.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 60\n",
            "\n",
            "The model response is not relevant to the instruction. The instruction is to generate a humorous anecdote, while the model response is about a party. The model response is not humorous and does not complete the instruction.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:   7%|         | 8/110 [00:29<06:25,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 100\n",
            "\n",
            "The input instruction is to identify the correct spelling of the word 'recieve' or 'receive'. The model response correctly identifies the word as 'receive', which is the correct spelling. Therefore, the score for this response is 100.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:   8%|         | 9/110 [00:34<07:24,  4.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The sentence created using the word \"nostalgia\" is:\n",
            "\n",
            "**Nostalgia washed over her as she looked through the old photos.**\n",
            "\n",
            "This sentence is well-constructed and accurately reflects the instruction. The use of the word \"nostalgia\" is appropriate and the sentence flow is smooth. However, it could be improved by adding more details or context to the sentence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:   9%|         | 10/110 [00:44<10:07,  6.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "**Response:**\n",
            "\n",
            "Prime numbers: 11, 19\n",
            "Composite numbers: 14\n",
            "\n",
            "The numbers 11, 14, and 19 are classified as follows:\n",
            "\n",
            "* **11** is prime because it is divisible by only 1 and itself.\n",
            "* **14** is composite because it is divisible by 1, 2, 7, and 14.\n",
            "* **19** is prime because it is divisible by only 1 and itself.\n",
            "\n",
            "Therefore, the prime numbers in the list are 11 and 19, and the composite number is 14.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  10%|         | 11/110 [00:47<08:27,  5.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is: 100\n",
            "\n",
            "The instruction is to write a response to the question \"What is the capital of Denmark?\" and the model response is exactly the answer to the question.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  11%|         | 12/110 [00:51<07:33,  4.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is: 100\n",
            "\n",
            "The instruction is to write the opposite of the word 'wet'. The answer is 'dry'. The model has correctly identified the opposite of 'wet' and therefore scored 100%.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  12%|        | 13/110 [00:54<06:41,  4.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Answer:** 80\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "The sentence \"Did you finish the report?\" is an interrogative sentence. The sentence is asking a question, so it is an interrogative sentence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  13%|        | 14/110 [00:56<05:35,  3.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 100\n",
            "\n",
            "The chemical symbol for mercury is Hg. This is accurate and concisely answers the question.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  14%|        | 15/110 [01:02<07:05,  4.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The text describes active transport as the movement of molecules across a cell membrane from a region of lower concentration to a region of higher concentration. This process is crucial for maintaining cellular homeostasis.\n",
            "\n",
            "However, the text does not explain the mechanism of active transport or the energy requirements for this process. Therefore, the text does not fully complete the instruction.\n",
            "\n",
            "**Therefore, I would score the text as 80 out of 100.**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  15%|        | 16/110 [01:10<08:23,  5.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "The model response is well-classified and accurately matches the input items with their respective states of matter.\n",
            "\n",
            "**Solid:**\n",
            "- Mercury is a liquid. This is incorrect, but the model has correctly classified Mercury as a liquid.\n",
            "\n",
            "**Liquid:**\n",
            "- Oxygen is a gas. This is accurate.\n",
            "\n",
            "**Gas:**\n",
            "- Wood is a solid. This is also accurate.\n",
            "\n",
            "The model has correctly classified all three items, albeit with one minor inaccuracy. Therefore, the score is 90.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  15%|        | 17/110 [01:14<07:55,  5.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 100\n",
            "\n",
            "The conversion factor for kilometers to meters is 1000. Therefore, 3 kilometers is equal to 3 * 1000 = 3000 meters.\n",
            "\n",
            "The response is:\n",
            "\n",
            "**3 kilometers is 3000 meters.**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  16%|        | 18/110 [01:18<07:19,  4.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 100\n",
            "\n",
            "The sentence: Someone left a note.\n",
            "\n",
            "The corrected sentence: A note was left by someone.\n",
            "\n",
            "The sentence has been converted using an indefinite pronoun correctly. The pronoun \"someone\" has been replaced with \"a note was left by someone.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  17%|        | 19/110 [01:24<07:52,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The model response is grammatically correct and provides an appropriate synonym for 'excited', which is 'thrilled'. However, the synonym 'enthusiastic' is not as close in meaning to 'excited' as 'thrilled'. Enthusiastic implies a high level of interest or passion, while excited typically refers to a feeling of intense joy or happiness. Therefore, the score of 80 is appropriate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  18%|        | 20/110 [01:31<08:19,  5.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "The sentence generated is: \"Never have I ever traveled without a map.\"\n",
            "\n",
            "The model response is: \"Never have I ever without without.\"\n",
            "\n",
            "**Score:** 20\n",
            "\n",
            "The model response is not only incomplete but also grammatically incorrect. The sentence pattern is \"Never have I ever _____ without _____,\" but the model response does not fill in the blanks appropriately. The sentence should be \"Never have I ever traveled without a map.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  19%|        | 21/110 [01:34<07:05,  4.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "The adjective from the list is 'tall.'\n",
            "\n",
            "**Score:** 0\n",
            "\n",
            "The model response incorrectly identified 'quick' as the adjective from the list, rather than 'tall.'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  20%|        | 22/110 [01:38<06:39,  4.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "1000 grams is equal to 1 kilogram.\n",
            "\n",
            "**Score:** 100\n",
            "\n",
            "The conversion factor is 1000 grams = 1 kilogram. Therefore, 1000 grams is equal to 1 kilogram.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  21%|        | 23/110 [01:41<05:58,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is incorrect. The opposite of 'deep' is 'shallow'.\n",
            "\n",
            "**Score:** 20/100\n",
            "\n",
            "The model has confused the word 'deep' with the word 'light'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  22%|       | 24/110 [01:45<05:51,  4.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "Fish: Shark, Trout\n",
            "Mammals: Dolphin\n",
            "\n",
            "**Score:** 90\n",
            "\n",
            "The input list contains animals, including sharks, dolphins, and trout. Sharks and trout are fish, while dolphins are mammals. Therefore, the categorization is accurate and complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  23%|       | 25/110 [01:48<05:10,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is not accurate. The translation of 'library' to Spanish is 'biblioteca', not 'lmite'.\n",
            "\n",
            "**Score:** 20/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  24%|       | 26/110 [01:54<06:07,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The definition of hyperbole is:\n",
            "\n",
            "Hyperbole is a figure of speech that involves an exaggeration of ideas for the sake of emphasis.\n",
            "\n",
            "This definition is concise, accurate, and captures the essence of the term hyperbole. It correctly states that hyperbole is a figure of speech that involves exaggeration for emphasis, and it also mentions the purpose of exaggeration, which is to make the ideas more dramatic.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  25%|       | 27/110 [01:57<05:49,  4.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 20\n",
            "\n",
            "The translation \"Hello\" to Russian is \" (Privet)\". The model's response \"The Russian translation of 'Hello' is ' '\" is incorrect. The correct translation is \" (Privet)\".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  25%|       | 28/110 [02:01<05:37,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The definition of kinetic energy is:\n",
            "\n",
            "**Kinetic energy is the energy that an object possesses due to its motion.**\n",
            "\n",
            "This definition accurately describes the concept of kinetic energy, which is the energy possessed by an object because of its motion.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  26%|       | 29/110 [02:05<05:18,  3.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is: 100\n",
            "\n",
            "The instruction is to write the opposite of the word 'hot'. The answer is 'cold'. The model has correctly identified the opposite of 'hot' and therefore scored 100%.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  27%|       | 30/110 [02:11<06:19,  4.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 20\n",
            "\n",
            "The instruction is to convert 5 miles to kilometers. The formula for converting miles to kilometers is 1 mile = 1.613 kilometers.\n",
            "\n",
            "Therefore, 5 miles is approximately 5 * 1.613 = 8.05 kilometers.\n",
            "\n",
            "The model response \"5 miles is 5000 meters.\" is incorrect as 5 miles is not equal to 5000 meters.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  28%|       | 31/110 [02:16<06:08,  4.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is:\n",
            "\n",
            "```\n",
            "The chemical formula for magnesium sulfate is MgSO4.\n",
            "```\n",
            "\n",
            "The input instruction is asking for the chemical formula for magnesium sulfate. The model response correctly identifies the chemical formula for magnesium sulfate as MgSO4. Therefore, the score for this response is 100.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  29%|       | 32/110 [02:19<05:29,  4.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: Sure, here is the corrected output:\n",
            "\n",
            "**It's a piece of cake.**\n",
            "\n",
            "The corrected output is:\n",
            "\n",
            "**It's very easy.**\n",
            "\n",
            "The score for this model response is 90.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  30%|       | 33/110 [02:24<05:35,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "The model response perfectly lists five different types of vegetables as requested in the instruction. However, it includes an additional vegetable, \"Carrot,\" which is not listed in the input instruction. This minor error warrants a score of 90, as the majority of the requested task is completed accurately.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  31%|       | 34/110 [02:27<05:10,  4.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "7 kilometers is 7000 meters.\n",
            "\n",
            "**Score:** 100\n",
            "\n",
            "The conversion factor is 1000. Therefore, 7 kilometers is equal to 7000 meters.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  32%|      | 35/110 [02:31<04:52,  3.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is: 100\n",
            "\n",
            "The instruction is to write the opposite of the word 'heavy'. The answer is 'light'. The model has correctly identified the opposite of 'heavy' and therefore scored 100%.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  33%|      | 36/110 [02:34<04:35,  3.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is: 80\n",
            "\n",
            "The past tense of 'sing' is 'sang.' This is the correct answer. The model has correctly identified the past tense of 'sing' and used the correct verb form.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  34%|      | 37/110 [02:36<03:44,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is perfect and matches the instruction perfectly. The score is 100.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  35%|      | 38/110 [02:38<03:16,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "The plants were watered by the gardener.\n",
            "\n",
            "This is the converted sentence in passive voice.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  35%|      | 39/110 [02:40<03:00,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is: 100\n",
            "\n",
            "The past tense of 'throw' is 'threw'. This is a correct answer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  36%|      | 40/110 [02:50<05:33,  4.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The input instruction is to explain what a sonnet is. The model response correctly defines a sonnet as a 14-line poem with a specific rhyme scheme and meter, mentioning iambic pentameter. However, the response does not explain the rhyme scheme or meter in detail, and it does not mention the optional octave or sestet structure of sonnets.\n",
            "\n",
            "**Areas for improvement:**\n",
            "\n",
            "* Explain the rhyme scheme and meter of a sonnet more thoroughly.\n",
            "* Discuss the optional octave and sestet structure of sonnets.\n",
            "* Provide examples of sonnet forms.\n",
            "\n",
            "**Overall, this response is well-written and informative, but it could be improved by providing more details and examples.**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  37%|      | 41/110 [02:54<05:13,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The score for the model response is 20.\n",
            "\n",
            "The sentence generated by the model is \"She was very innovative and always had a new idea.\" This sentence does not use the word \"innovative\" in the context of the task, therefore it does not appropriately complete the request.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  38%|      | 42/110 [02:55<04:10,  3.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 100\n",
            "\n",
            "The plural form of 'cactus' is 'cacti'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  39%|      | 43/110 [02:59<03:58,  3.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is not appropriate. The correct translation is 'Wo ist die Toilette?'. The model response is 'Wie es ber das?'. This response is only 10% accurate.\n",
            "\n",
            "Score: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  40%|      | 44/110 [03:02<03:48,  3.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Answer:** 90\n",
            "\n",
            "The past-tense verb that describes a person laughing is \"laughed.\" The sentence is \"He laughed.\"\n",
            "\n",
            "The model response is \"He laughed.\" which is the correct answer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  41%|      | 45/110 [03:07<04:16,  3.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 60\n",
            "\n",
            "The sentence generated using the word \"transient\" is: \"The transient nature of her visit left a lasting impression.\"\n",
            "\n",
            "The model response \"She was transported from the park to the library by a transient\" does not use the word \"transient\" in the context of the instruction. Therefore, the score is 60.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  42%|     | 46/110 [03:11<04:07,  3.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is not aligned with the instruction. The instruction asks for a sentence using the word \"optimistic,\" while the model response uses the phrase \"She was optimistic about the future.\"\n",
            "\n",
            "Therefore, the score for this model response is 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  43%|     | 47/110 [03:17<04:57,  4.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The re-worded sentence using an indirect question is:\n",
            "\n",
            "**Could you tell me what time the meeting is?**\n",
            "\n",
            "The model response is:\n",
            "\n",
            "**The meeting is at the time indicated.**\n",
            "\n",
            "This response is an indirect question, as it asks the user to provide information about the time of the meeting, rather than directly stating the time. The response is also concise and to the point, and it uses the correct grammar and syntax.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  44%|     | 48/110 [03:20<04:16,  4.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "The sentence \"What a beautiful day!\" is an exclamation.\n",
            "\n",
            "**Score:** 100\n",
            "\n",
            "The sentence is an exclamation because it expresses joy and excitement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  45%|     | 49/110 [03:22<03:36,  3.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 100\n",
            "\n",
            "The opposite of 'rich' is 'poor'. This is a straightforward and accurate answer to the question.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  45%|     | 50/110 [03:26<03:28,  3.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "The synonym for the word \"begin\" is \"commence.\"\n",
            "\n",
            "**Score:** 100\n",
            "\n",
            "The model has successfully identified the synonym for the word \"begin\" and provided the correct answer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  46%|     | 51/110 [03:30<03:46,  3.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:** 0\n",
            "\n",
            "The text \"The birds sings beautiful songs.\" has several errors, including the misspelling of the plural noun \"birds\" and the incorrect verb conjugation \"sings.\" The corrected text is \"The birds sing beautiful songs.\"\n",
            "\n",
            "The model response is incorrect as it has not corrected the errors in the text.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  47%|     | 52/110 [03:34<03:36,  3.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Model Response:**\n",
            "\n",
            "Could you help me tomorrow?\n",
            "\n",
            "**Score:** 100\n",
            "\n",
            "The model response perfectly transforms the input sentence into a question using \"could.\" The syntax and grammar are correct, and the intent is clear.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  48%|     | 53/110 [03:39<03:56,  4.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The model response is mostly correct, but there is one error. The item \"bicycle\" should be classified under \"Electronics\", not \"Vehicles\".\n",
            "\n",
            "**Corrected Response:**\n",
            "\n",
            "**Vehicles:** Bicycle\n",
            "**Plants:** Rose\n",
            "**Animals:** Tiger\n",
            "\n",
            "**Overall, the model response is well-classified, with only one minor error.**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  49%|     | 54/110 [03:43<03:51,  4.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 20\n",
            "\n",
            "The model response is not only incorrect but also completely unrelated to the instruction. The instruction asks for the definition of the term 'irony', but the model response defines the term 'silly'. This is not only off-topic but also completely inaccurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  50%|     | 55/110 [03:47<03:43,  4.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is not appropriate. The correct translation is 'Willkommen', not 'Wie es tut mir?'.\n",
            "\n",
            "**Score:** 60\n",
            "\n",
            "The translation is accurate, but the use of the phrase 'Wie es tut mir?' is not appropriate in this context.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  51%|     | 56/110 [03:52<04:03,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The primary function of the human heart is to pump blood throughout the body, delivering oxygen and nutrients to tissues and removing carbon dioxide and other wastes. The heart is a vital organ that plays a crucial role in maintaining homeostasis and sustaining life. Its primary function is to circulate blood, ensuring that oxygen and nutrients are distributed to the cells and that waste products are removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  52%|    | 57/110 [03:58<04:15,  4.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The sentence: He is reading a novel inspired by his grandmother.\n",
            "\n",
            "The reworded sentence: He will be reading a novel inspired by his grandmother.\n",
            "\n",
            "The sentence is in the present tense, so the reworded sentence should be in the future tense. The correct reworded sentence is \"He will be reading a novel inspired by his grandmother.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  53%|    | 58/110 [04:04<04:23,  5.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "**Response:**\n",
            "\n",
            "The government passed the law.\n",
            "\n",
            "The original sentence is in passive voice. To convert it to active voice, we simply change the sentence structure and move the subject to the front of the sentence. The new sentence is:\n",
            "\n",
            "The government passed the law.\n",
            "\n",
            "This is an accurate and concise conversion that maintains the original meaning of the sentence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  54%|    | 59/110 [04:09<04:21,  5.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 20\n",
            "\n",
            "The sentence created by the model is \"The storm was inevitable.\" This sentence does not match the instruction, as the instruction asks for a sentence using the word \"inevitable\" in relation to the task of writing a sentence. The model's response is unrelated to the task and does not use the word \"inevitable\" at all.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  55%|    | 60/110 [04:13<04:00,  4.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "Opinion-based.\n",
            "\n",
            "**Score:** 90\n",
            "\n",
            "The sentence \"Chocolate is the best dessert\" is opinion-based because it is a subjective statement that is not based on facts. There is no objective truth to whether chocolate is the best dessert or not.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  55%|    | 61/110 [04:16<03:24,  4.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "The antonym of 'old' is 'young'. This is a simple antonym relationship that can be easily found using a thesaurus.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  56%|    | 62/110 [04:21<03:38,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The model response \"A synonym for 'hardworking' is 'smart'\" is not appropriate. The word 'smart' is not a synonym for 'hardworking'. 'Smart' is a word that describes someone who is quick to learn and understand things, while 'hardworking' is a word that describes someone who is dedicated and persistent in their work.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  57%|    | 63/110 [04:27<03:49,  4.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is incorrect. The boiling point of sulfur is 444.6 degrees Celsius, not -114.5 degrees Celsius.\n",
            "\n",
            "**Score:** 0/100\n",
            "\n",
            "The model has completely misunderstood the instruction and provided an incorrect answer. The instruction asks for the boiling point of sulfur in Celsius, but the model has provided the freezing point of sulfur in Celsius.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  58%|    | 64/110 [04:29<03:06,  4.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 0\n",
            "\n",
            "The model response is completely incorrect. The plural form of 'child' is 'children', not 'chunk'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  59%|    | 65/110 [04:33<03:06,  4.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is:\n",
            "\n",
            "```\n",
            "An antonym of 'complicated' is 'simplified'.\n",
            "```\n",
            "\n",
            "The input instruction is to write an antonym of 'complicated'. The antonym of 'complicated' is 'simple'. The model response is correct.\n",
            "\n",
            "**Score:** 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  60%|    | 66/110 [04:37<02:55,  3.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The response is mostly accurate, but it incorrectly states \"water vapor in the air\" instead of \"water vapor\" as one of the forms of water. Otherwise, the response is well-written and concise.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  61%|    | 67/110 [04:43<03:15,  4.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "The sentence to be rewritten as a question is:\n",
            "\n",
            "The dog chased the cat.\n",
            "\n",
            "The rewritten question is:\n",
            "\n",
            "Did the dog chase the cat?\n",
            "\n",
            "**Score:** 90\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "The original sentence is in the form of a statement, while the rewritten question is in the form of a question. The question is clear and concise, and it accurately reflects the original sentence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  62%|   | 68/110 [04:48<03:23,  4.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "**Response:**\n",
            "\n",
            "The movie was long. It was interesting.\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "The sentence is split into two declarative sentences as requested. The first sentence is \"The movie was long.\" The second sentence is \"It was interesting.\"\n",
            "\n",
            "The response is well-written and accurately completes the request. It is clear, concise, and grammatically correct.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  63%|   | 69/110 [04:58<04:22,  6.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The model response is mostly accurate, but there is an error in classifying Soap as an acid. Soap is a base, not an acid. The model has correctly classified Lemon juice as an acid and Water as neutral.\n",
            "\n",
            "**Suggestions:**\n",
            "\n",
            "* The model should have classified Soap as a base instead of an acid.\n",
            "* The model should have stated the reason for classifying Soap as a base, such as \"Soap is a base because it contains hydroxide ions.\"\n",
            "\n",
            "**Overall:**\n",
            "\n",
            "The model response is well-written and demonstrates a good understanding of the concepts of acid, base, and neutral substances. However, the error in classifying Soap as an acid detracts from the overall accuracy of the response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  64%|   | 70/110 [05:02<03:45,  5.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 60\n",
            "\n",
            "The model response \"A synonym for 'sad' is 'angry'\" is not appropriate. The instruction asks for a synonym of 'sad', but the model response is 'angry'. 'Angry' is not a synonym of 'sad'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  65%|   | 71/110 [05:10<04:10,  6.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The sentence \"I prefer homemade cookies to store boaght.\" has the following spelling mistakes:\n",
            "\n",
            "- boaght\n",
            "- store\n",
            "\n",
            "The corrected sentence is \"I prefer homemade cookies to store bought.\"\n",
            "\n",
            "The model response correctly identified and corrected all the spelling mistakes in the input sentence. However, the sentence structure could be improved. The use of the word \"store\" in the sentence is not ideal. A more appropriate word to use would be \"keep\" or \"preserve.\"\n",
            "\n",
            "Overall, the model response is well-written and demonstrates a good understanding of the task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  65%|   | 72/110 [05:15<03:43,  5.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 60\n",
            "\n",
            "The sentence generated by the model is not aligned with the instruction. The instruction asks for a sentence using the word \"transient,\" while the model's sentence uses the word \"transported.\" The sentence also lacks context and does not describe the task of writing a sentence using the word \"transient.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  66%|   | 73/110 [05:21<03:36,  5.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "The translation of \"I am lost\" to Italian is \"Mi sono perso\" (if male) or \"Mi sono persa\" (if female).\n",
            "\n",
            "This translation is accurate and concise, and it correctly identifies the gender-specific nuances of the sentence. The use of the phrase \"il pi amricaino\" is a humorous touch that is appropriate for the context of the sentence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  67%|   | 74/110 [05:24<03:05,  5.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Output:** 90\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "The text \"This manual provides instructions for installing the software.\" is a technical document. It provides instructions on how to install software. Therefore, the text is classified as a technical document.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  68%|   | 75/110 [05:27<02:37,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "The list is sorted in descending order as:\n",
            "\n",
            "25, 16, 10, 7, 2.\n",
            "\n",
            "The list is sorted in descending order.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  69%|   | 76/110 [05:35<03:01,  5.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "The model response \"Can I have some water?\" is a perfect translation of the input \"Can I have some water?\" into French. The response is grammatically correct and accurately captures the meaning of the input. The only minor deviation from the perfect translation is the use of the phrase \"avoir de l'eau\" instead of \"avoir de l'eau ?\" (with a question mark). However, this is a minor issue that does not significantly impact the overall accuracy of the response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  70%|   | 77/110 [05:40<03:00,  5.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The simile \"Her hands were as cold as ice\" is appropriately completed with the response \"The temperature of 'as cold as' is -38 degrees Celsius.\"\n",
            "\n",
            "The response is well-written and accurately completes the instruction. It uses the correct simile structure and provides a precise temperature measurement. However, the response could be improved by being more concise and by using more vivid language.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  71%|   | 78/110 [05:43<02:30,  4.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "**Response:**\n",
            "\n",
            "Swim: Verb\n",
            "Beautiful: Adjective\n",
            "Quickly: Adverb\n",
            "\n",
            "The words are classified correctly. The grammar categories are appropriate for each word.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  72%|  | 79/110 [05:50<02:46,  5.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The density of an object is defined as its mass per unit volume. Given an object with a mass of 15 grams and a volume of 5 cubic centimeters, we can calculate its density as:\n",
            "\n",
            "Density = Mass / Volume\n",
            "\n",
            "Substituting these values into the formula, we get:\n",
            "\n",
            "Density = 15 grams / 5 cubic centimeters = 3 grams per cubic centimeter\n",
            "\n",
            "Therefore, the density of the object is 3 grams per cubic centimeter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  73%|  | 80/110 [05:53<02:16,  4.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is: 100\n",
            "\n",
            "The text \"The abbreviation for 'Master of Business Administration' is MBA.\" is grammatically correct and accurately answers the question.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  74%|  | 81/110 [05:55<01:47,  3.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The number IX in Roman numerals is 9.\n",
            "\n",
            "The number IX is equivalent to 9 in decimal.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  75%|  | 82/110 [05:57<01:34,  3.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 100\n",
            "\n",
            "The opposite of 'horizontal' is 'vertical'. This is because the two words are opposites of each other in the direction of orientation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  75%|  | 83/110 [05:59<01:20,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is completely unrelated to the instruction and does not answer the question. The score for this response is 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  76%|  | 84/110 [06:03<01:20,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "**Response:**\n",
            "\n",
            "He remained very calm.\n",
            "\n",
            "The original sentence \"He was as cool as a cucumber.\" is a clich. The corrected sentence \"He remained very calm.\" is not a clich.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  77%|  | 85/110 [06:05<01:12,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "The main verb in the sentence is 'barked'. The verb 'barked' is the main verb in the sentence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  78%|  | 86/110 [06:09<01:16,  3.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The sentence generated by the model is not related to the instruction. The instruction is to generate a sentence using the word 'elucidate', while the model generated sentence is unrelated to the instruction. Therefore, the score is 80.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  79%|  | 87/110 [06:16<01:42,  4.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Answer:** 80\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "The sentence \"Me and my friend went to the store.\" has several errors. The correct sentence is \"My friend and I went to the store.\"\n",
            "\n",
            "The model response \"We went to the store.\" is grammatically correct, but it does not match the input sentence exactly. The model did not correct the pronoun \"Me\" to \"My friend\" and also added the word \"We\".\n",
            "\n",
            "Overall, the model's response is well-written, but it could be improved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  80%|  | 88/110 [06:20<01:31,  4.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is not relevant to the instruction. The instruction is asking for the formula for calculating work done, while the model response is a list of unrelated characters. Therefore, I cannot score the model response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  81%|  | 89/110 [06:22<01:16,  3.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is incorrect. The chemical formula for ammonium nitrate is NH4NO3, not NH3.\n",
            "\n",
            "**Score:** 20/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  82%| | 90/110 [06:26<01:15,  3.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is incorrect. The molecular formula for water is H2O, not H2O2.\n",
            "\n",
            "**Score:** 0\n",
            "\n",
            "The model has made a mistake in the molecular formula for water. The correct formula is H2O, not H2O2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  83%| | 91/110 [06:29<01:05,  3.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The food was not good, but it could use some improvement. The sentence is describing the food as being unsatisfactory, but it could be made better.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  84%| | 92/110 [06:33<01:05,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The opposite of 'lazy' is 'diligent'. The model response is correct, but it could be improved. The response is well-written, but the word 'attentive' is not as closely related to 'lazy' as 'diligent'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  85%| | 93/110 [06:37<01:04,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The model response correctly identifies two out of the three essential vitamins for human health: Vitamin C and Vitamin D. However, it incorrectly identifies Vitamin B12 and Vitamin B6 instead of Vitamin A. Therefore, the score is 80%.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  85%| | 94/110 [06:40<00:56,  3.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The definition of simile is:\n",
            "\n",
            "A simile is a figure of speech that directly compares two different things, often introduced with the words 'like' or 'as'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  86%| | 95/110 [06:43<00:49,  3.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is incorrect. The boiling point of chlorine is -34 degrees Celsius, not -196 degrees Celsius.\n",
            "\n",
            "Score: 20/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  87%| | 96/110 [06:46<00:46,  3.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is not aligned with the instruction. The instruction asks for the translation of \"My name is\" into French, while the model response is \"Comment a va?\". Therefore, the score for this model response is 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  88%| | 97/110 [06:50<00:44,  3.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 90\n",
            "\n",
            "The conversion factor is 100 centimeters = 1 meter.\n",
            "\n",
            "200 centimeters is equal to 2 meters.\n",
            "\n",
            "Therefore, the conversion is 200 centimeters is 2 meters.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  89%| | 98/110 [06:51<00:33,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 100\n",
            "\n",
            "The chemical symbol for zinc is Zn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  90%| | 99/110 [06:54<00:29,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The formula for calculating force is Force = mass x acceleration. This formula accurately describes the relationship between force, mass, and acceleration.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  91%| | 100/110 [07:01<00:39,  3.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The sentence generated by the model is:\n",
            "\n",
            "**The company's innovative approach set it apart from its competitors.**\n",
            "\n",
            "This sentence is grammatically correct and uses the word \"innovative\" appropriately. It also accurately reflects the instruction to generate a sentence using the word \"innovative.\" However, the sentence could be improved by using more specific language to describe the company's innovative approach, such as \"The company's groundbreaking approach set it apart from its competitors.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  92%|| 101/110 [07:04<00:34,  3.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is not aligned with the instruction. The instruction asks for a sentence using the word \"generous,\" but the model response uses the word \"gave\" instead. Therefore, the score for this model response is 60.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  93%|| 102/110 [07:08<00:31,  3.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The antonym of 'sharp' is 'dull'. The model response correctly identifies the antonym of 'sharp' as 'dull'. However, the response could be improved by using more precise language, such as 'blunt' or 'obtuse'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  94%|| 103/110 [07:15<00:33,  4.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 20\n",
            "\n",
            "The text describes the basic structure of a neuron, but it is incorrect. A neuron is not a synapse. A neuron is a specialized cell in the nervous system that transmits electrical signals. It consists of a cell body, dendrites, and an axon. The cell body contains the nucleus, which is the control center of the neuron. Dendrites receive signals from other neurons, and the axon transmits signals to other neurons, muscles, or glands.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  95%|| 104/110 [07:18<00:25,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Answer:** 80\n",
            "\n",
            "The translation of \"see you later\" to Spanish is \"hasta luego\". The model response is mostly correct, but it includes the unnecessary phrase \" estoy\" which lowers the score.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  95%|| 105/110 [07:30<00:33,  6.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "The text provided describes the Fibonacci sequence, which is a series of numbers in which each number is the sum of the previous two numbers in the sequence, starting from the first two numbers in the sequence, which are 0 and 1.\n",
            "\n",
            "The text also specifies that the first 10 elements of the sequence should be listed.\n",
            "\n",
            "The text does not specify the order in which the elements should be listed, so I have listed them in the order that they appear in the sequence.\n",
            "\n",
            "The text also does not specify the format of the output, so I have used the same format as the text provided.\n",
            "\n",
            "Overall, this response is well-written and accurately completes the request. However, it could be improved by listing the elements in the order they appear in the sequence, and by formatting the output in a more consistent manner.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  96%|| 106/110 [07:33<00:21,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 20\n",
            "\n",
            "The antonym of 'transparent' is 'opaque'. The model response incorrectly stated 'illuminate' as an antonym, which is not correct.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  97%|| 107/110 [07:36<00:14,  4.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: The model response is: 50\n",
            "\n",
            "The past tense of 'think' is 'thought'. This is the correct answer. However, the model response is not perfect as it uses the phrase \"to think\" instead of \"thought\".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  98%|| 108/110 [07:40<00:08,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "The classification of the sentence \"Please open the door.\" is imperative.\n",
            "\n",
            "**Score:** 90\n",
            "\n",
            "The sentence is an imperative sentence, as it is a command or instruction.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScoring entries:  99%|| 109/110 [07:43<00:04,  4.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Score:** 80\n",
            "\n",
            "**Response:**\n",
            "\n",
            "She never forgets to call.\n",
            "\n",
            "The sentence has been rewritten to use a negative adverb. The original sentence is \"She always remembers to call.\" The corrected sentence is \"She never forgets to call.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring entries: 100%|| 110/110 [07:49<00:00,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert score: **Response:**\n",
            "\n",
            "The conversion formula for miles per hour to kilometers per hour is 1.613.\n",
            "\n",
            "50 miles per hour is approximately 50 x 1.613 = 80.47 kilometers per hour.\n",
            "\n",
            "**Score:** 90\n",
            "\n",
            "The model response is incorrect. The conversion formula should be 1.613, not 1.61.\n",
            "\n",
            "Scored 0 items.\n",
            "Average score: nan\n",
            "\n",
            "Saved per-item scores to: gemma_judge_scores.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0a583bedb654a82b10505d09c5f3f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_7d7c78b582a64b14917fdb792fb8cdc8"
          }
        },
        "e2deedc72968430aa8f9f74d75673739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23b32bd5d2384300908d5a5d339c150b",
            "placeholder": "",
            "style": "IPY_MODEL_21148aae610e4fa0bd6445d1dbe67d8c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "9e795ff0fd33427b9e249f684a7d60ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f37b3d96718c4261b11e9c9ebc91c35e",
            "placeholder": "",
            "style": "IPY_MODEL_f0ce4255e9384614a01d8beacc392c06",
            "value": ""
          }
        },
        "fa44783995044fbc9e50695e884650d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_264e9f4b2b5948b9af20dd0bced11bb5",
            "style": "IPY_MODEL_12821b4ce74943e6949bf3d362061f08",
            "value": true
          }
        },
        "e18ca82d2e2c45c48d81e8208a7c4f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_035ed32af0224b9fb3e72ade7b686ee0",
            "style": "IPY_MODEL_2cb0642e017c4cc5a85fff6e26ae30b5",
            "tooltip": ""
          }
        },
        "9cff097dfa4b46bd8df0bc7088389e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5383dd5faf774f42ab2b302f3f55c502",
            "placeholder": "",
            "style": "IPY_MODEL_21bbca06eb5045dba9919601a84f3eed",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7d7c78b582a64b14917fdb792fb8cdc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "23b32bd5d2384300908d5a5d339c150b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21148aae610e4fa0bd6445d1dbe67d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f37b3d96718c4261b11e9c9ebc91c35e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ce4255e9384614a01d8beacc392c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "264e9f4b2b5948b9af20dd0bced11bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12821b4ce74943e6949bf3d362061f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "035ed32af0224b9fb3e72ade7b686ee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cb0642e017c4cc5a85fff6e26ae30b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5383dd5faf774f42ab2b302f3f55c502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21bbca06eb5045dba9919601a84f3eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0841771838c4bf997627206c334d9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad7967dfd1c94a1d9e16cf5259668037",
            "placeholder": "",
            "style": "IPY_MODEL_5cb460c0a25842e6ab7860717e221c63",
            "value": "Connecting..."
          }
        },
        "ad7967dfd1c94a1d9e16cf5259668037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cb460c0a25842e6ab7860717e221c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ca3f7b997234db3a12988b4f6003a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2147f4d48adc48d1868ace541208119c",
              "IPY_MODEL_7e6ce276f8b94d1d91094af28bc206d1",
              "IPY_MODEL_5079c0596feb4b668d4aff7b16349d0a"
            ],
            "layout": "IPY_MODEL_60da22588c064c0a8b930ca7c11279f5"
          }
        },
        "2147f4d48adc48d1868ace541208119c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eee9c21d9a9d4a1c8ffbb168a9a347e1",
            "placeholder": "",
            "style": "IPY_MODEL_fe1fbffc25f849e5935b650606110e8f",
            "value": "config.json:100%"
          }
        },
        "7e6ce276f8b94d1d91094af28bc206d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f36f61d7ac474546ba0da40ec88b3117",
            "max": 694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd39412faa96400aa70a50e9643783b2",
            "value": 694
          }
        },
        "5079c0596feb4b668d4aff7b16349d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5062645f605b434ca9407c0661218ca3",
            "placeholder": "",
            "style": "IPY_MODEL_aada674efbd64805b68dd7137cbcaa84",
            "value": "694/694[00:00&lt;00:00,77.7kB/s]"
          }
        },
        "60da22588c064c0a8b930ca7c11279f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee9c21d9a9d4a1c8ffbb168a9a347e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe1fbffc25f849e5935b650606110e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f36f61d7ac474546ba0da40ec88b3117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd39412faa96400aa70a50e9643783b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5062645f605b434ca9407c0661218ca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aada674efbd64805b68dd7137cbcaa84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f068319f9b6439e829189cb6582d8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5d1271a0d1d45b89dcf1c968363b626",
              "IPY_MODEL_c933ab7479444033aacad2a2976b18c9",
              "IPY_MODEL_e06aa4757eb64658ab010c28bd11ae2c"
            ],
            "layout": "IPY_MODEL_d6da6b8669df4453aa45a11daae8a302"
          }
        },
        "f5d1271a0d1d45b89dcf1c968363b626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_631fc20a92c54ad2a0be119346bb9698",
            "placeholder": "",
            "style": "IPY_MODEL_e3fe5c62979f46f1a2d0437107918a1b",
            "value": "model.safetensors.index.json:100%"
          }
        },
        "c933ab7479444033aacad2a2976b18c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c175cb302cb941a3a6eef70085dc83ce",
            "max": 20920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_801e738577a84b4eaf9d658acb826646",
            "value": 20920
          }
        },
        "e06aa4757eb64658ab010c28bd11ae2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8de19591f424c1baab9bf8ff06596ab",
            "placeholder": "",
            "style": "IPY_MODEL_1015620c16f948d1972d1feaf08f7c2b",
            "value": "20.9k/20.9k[00:00&lt;00:00,2.49MB/s]"
          }
        },
        "d6da6b8669df4453aa45a11daae8a302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631fc20a92c54ad2a0be119346bb9698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3fe5c62979f46f1a2d0437107918a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c175cb302cb941a3a6eef70085dc83ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "801e738577a84b4eaf9d658acb826646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8de19591f424c1baab9bf8ff06596ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1015620c16f948d1972d1feaf08f7c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c276461a5d09461cb42dbd988c689557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62e5304fcb1d45179384b8d713b5ac28",
              "IPY_MODEL_258a9c77d34c431899f4061b9999f4a2",
              "IPY_MODEL_02e00a7a66494440932a1ccd84db162c"
            ],
            "layout": "IPY_MODEL_2747481db70c4df0b7cefedcf8b78cac"
          }
        },
        "62e5304fcb1d45179384b8d713b5ac28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0437ef801bb4409cace7864a606a0433",
            "placeholder": "",
            "style": "IPY_MODEL_ee78d74af7a648bcad02b27bb26984b0",
            "value": "Fetching4files:100%"
          }
        },
        "258a9c77d34c431899f4061b9999f4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb6a0b385fe483badaf0aeb6aa9647b",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fba63b261a4049afa864c53b54104c38",
            "value": 4
          }
        },
        "02e00a7a66494440932a1ccd84db162c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72d2a843350847b9b7a20eaa5b56cf20",
            "placeholder": "",
            "style": "IPY_MODEL_aaa4f22ad9634d14b3bfaf91649417a9",
            "value": "4/4[09:19&lt;00:00,559.26s/it]"
          }
        },
        "2747481db70c4df0b7cefedcf8b78cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0437ef801bb4409cace7864a606a0433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee78d74af7a648bcad02b27bb26984b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bb6a0b385fe483badaf0aeb6aa9647b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba63b261a4049afa864c53b54104c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72d2a843350847b9b7a20eaa5b56cf20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa4f22ad9634d14b3bfaf91649417a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20bc7d2347c14908b357e1bcee0ffb29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dae06a15d7c4d47971cf14985ed66cb",
              "IPY_MODEL_2796455526254859ba3927306b0caa01",
              "IPY_MODEL_2c8f07b1c4134e86b63678adf2a75938"
            ],
            "layout": "IPY_MODEL_f679feab502b4e2bb883ce551acec3c3"
          }
        },
        "2dae06a15d7c4d47971cf14985ed66cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c65ad649ce254c0496dc3c607eae01b4",
            "placeholder": "",
            "style": "IPY_MODEL_9d4efa3edee748e085dee3bfed48f18c",
            "value": "model-00004-of-00004.safetensors:100%"
          }
        },
        "2796455526254859ba3927306b0caa01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d752338b47f04722bef97c87de1bb48b",
            "max": 2113988336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f23dd9973d94c9a82a949a96cc0d82d",
            "value": 2113988336
          }
        },
        "2c8f07b1c4134e86b63678adf2a75938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd44e4924ccf4a2188bad3087d5f4c81",
            "placeholder": "",
            "style": "IPY_MODEL_7b25e494998049cd8c5d29a95880a849",
            "value": "2.11G/2.11G[06:05&lt;00:00,2.02MB/s]"
          }
        },
        "f679feab502b4e2bb883ce551acec3c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c65ad649ce254c0496dc3c607eae01b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4efa3edee748e085dee3bfed48f18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d752338b47f04722bef97c87de1bb48b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f23dd9973d94c9a82a949a96cc0d82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd44e4924ccf4a2188bad3087d5f4c81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b25e494998049cd8c5d29a95880a849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c79d2b2cba1c43479ba7949933fd027d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab6bcd3eafbe46f2b2f9b874c1ed1e2c",
              "IPY_MODEL_59da91f5a0224b84a5669a08fc0a41fe",
              "IPY_MODEL_46f0dc67813848ceb2876b071c2d1ee5"
            ],
            "layout": "IPY_MODEL_b7f27f8ae0a54239ad992bfe398f753d"
          }
        },
        "ab6bcd3eafbe46f2b2f9b874c1ed1e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8d35cef0eee4bab988168453dc3af06",
            "placeholder": "",
            "style": "IPY_MODEL_9ade9ce2a096413fa12ab402befff7ec",
            "value": "model-00003-of-00004.safetensors:100%"
          }
        },
        "59da91f5a0224b84a5669a08fc0a41fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5245b274e7bb46b695c716f6c54f32ed",
            "max": 4982953200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52879b038558492aaeb1cbb08bc50cca",
            "value": 4982953200
          }
        },
        "46f0dc67813848ceb2876b071c2d1ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44c6088f5fd048d289271952ed078809",
            "placeholder": "",
            "style": "IPY_MODEL_6aa0af963b1e4a9185d51678463ecf5b",
            "value": "4.98G/4.98G[09:16&lt;00:00,39.3MB/s]"
          }
        },
        "b7f27f8ae0a54239ad992bfe398f753d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d35cef0eee4bab988168453dc3af06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ade9ce2a096413fa12ab402befff7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5245b274e7bb46b695c716f6c54f32ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52879b038558492aaeb1cbb08bc50cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44c6088f5fd048d289271952ed078809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa0af963b1e4a9185d51678463ecf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87e18a1cbd46443ea1d0a614a575099d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0850869d952b41b580de763bb9a15970",
              "IPY_MODEL_8a31a2cf0ffa4a80a33cbb5df1a9df9c",
              "IPY_MODEL_fd12a8baab3a49b1a2a91616e169c64c"
            ],
            "layout": "IPY_MODEL_23e9d9b38e504b399261c14007eee440"
          }
        },
        "0850869d952b41b580de763bb9a15970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d797e87290434e83ab592c836a0e77",
            "placeholder": "",
            "style": "IPY_MODEL_3f28081bcc524b9ca01f890cc138f0cc",
            "value": "model-00001-of-00004.safetensors:100%"
          }
        },
        "8a31a2cf0ffa4a80a33cbb5df1a9df9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d825e1213ae5408e9c4c64b6d40dde06",
            "max": 4995496656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f922c22827c4c9caca54306df1076e9",
            "value": 4995496656
          }
        },
        "fd12a8baab3a49b1a2a91616e169c64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_250acf920eb04782bc09965ab037c97c",
            "placeholder": "",
            "style": "IPY_MODEL_f3351dea1cc0450186f32d1a2ee20336",
            "value": "5.00G/5.00G[09:19&lt;00:00,123MB/s]"
          }
        },
        "23e9d9b38e504b399261c14007eee440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d797e87290434e83ab592c836a0e77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f28081bcc524b9ca01f890cc138f0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d825e1213ae5408e9c4c64b6d40dde06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f922c22827c4c9caca54306df1076e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "250acf920eb04782bc09965ab037c97c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3351dea1cc0450186f32d1a2ee20336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17652f2c5669462594278408281823c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27c9622af97a450a9a67ae52ebecf641",
              "IPY_MODEL_d7c00740b4544a659b165efe834b7f14",
              "IPY_MODEL_548429346d5645eeb3a1eb9b9340c320"
            ],
            "layout": "IPY_MODEL_0cc3d3340f8141c7b1a0fd9e4d8d6932"
          }
        },
        "27c9622af97a450a9a67ae52ebecf641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89484001fd4c4baea991e684e7973157",
            "placeholder": "",
            "style": "IPY_MODEL_945c0420d870419297edf8846f366bed",
            "value": "model-00002-of-00004.safetensors:100%"
          }
        },
        "d7c00740b4544a659b165efe834b7f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6711053fb6749c1b5a3a3d7a6910a46",
            "max": 4982953168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02981208401041e4a1798cbd141ecce7",
            "value": 4982953168
          }
        },
        "548429346d5645eeb3a1eb9b9340c320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_250c85bdd200496c89936192fc310253",
            "placeholder": "",
            "style": "IPY_MODEL_9afa0665140d482ba459b83f53294c53",
            "value": "4.98G/4.98G[09:13&lt;00:00,43.8MB/s]"
          }
        },
        "0cc3d3340f8141c7b1a0fd9e4d8d6932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89484001fd4c4baea991e684e7973157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945c0420d870419297edf8846f366bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6711053fb6749c1b5a3a3d7a6910a46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02981208401041e4a1798cbd141ecce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "250c85bdd200496c89936192fc310253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9afa0665140d482ba459b83f53294c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67835dafdafe4f7fabeaaf7bf6d1518b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6fd276d6c61436682c699d350a39f50",
              "IPY_MODEL_b1d5d16d4dcf48bd8504762fd9b27d88",
              "IPY_MODEL_66884c0006524849824a5ec743043ff4"
            ],
            "layout": "IPY_MODEL_bdbb6982cf8e4dfc8faa690aa06a06c1"
          }
        },
        "a6fd276d6c61436682c699d350a39f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf5f6b798e94b02aa306145c2ce3119",
            "placeholder": "",
            "style": "IPY_MODEL_bae502726b9c43108317e15c94d5c920",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "b1d5d16d4dcf48bd8504762fd9b27d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f40acf959a4045d89647f08b7d96471d",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03c0698156e146b0b3b750f5e47dc111",
            "value": 4
          }
        },
        "66884c0006524849824a5ec743043ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_282cfadca0fa4715aba0f66dcf7fd6bc",
            "placeholder": "",
            "style": "IPY_MODEL_ccfe3c4bd3e74c459137617b3b547855",
            "value": "4/4[00:46&lt;00:00,12.02s/it]"
          }
        },
        "bdbb6982cf8e4dfc8faa690aa06a06c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf5f6b798e94b02aa306145c2ce3119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bae502726b9c43108317e15c94d5c920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f40acf959a4045d89647f08b7d96471d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c0698156e146b0b3b750f5e47dc111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "282cfadca0fa4715aba0f66dcf7fd6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccfe3c4bd3e74c459137617b3b547855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee475032449a4268821bcaf4f514b78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9af5edc639b431fba201c76f3b7add0",
              "IPY_MODEL_e99ad37eb9074d4584587b99e81e3648",
              "IPY_MODEL_125c603dc6a14d8caf109218091090eb"
            ],
            "layout": "IPY_MODEL_84e45dd177884294aa988b3e85d0e701"
          }
        },
        "e9af5edc639b431fba201c76f3b7add0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52376e5ea91d448a89a20729d33570ee",
            "placeholder": "",
            "style": "IPY_MODEL_84e60fb643d84943a6e40686881292aa",
            "value": "generation_config.json:100%"
          }
        },
        "e99ad37eb9074d4584587b99e81e3648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b68cb5fa608460f8e87946e06f0761a",
            "max": 137,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfb788b1e6904f268ba161418721f4c4",
            "value": 137
          }
        },
        "125c603dc6a14d8caf109218091090eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97217933b7524caf87a6c18a78d1061c",
            "placeholder": "",
            "style": "IPY_MODEL_39e82298349c4f9da6280d7131b9886f",
            "value": "137/137[00:00&lt;00:00,20.7kB/s]"
          }
        },
        "84e45dd177884294aa988b3e85d0e701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52376e5ea91d448a89a20729d33570ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e60fb643d84943a6e40686881292aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b68cb5fa608460f8e87946e06f0761a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfb788b1e6904f268ba161418721f4c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97217933b7524caf87a6c18a78d1061c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39e82298349c4f9da6280d7131b9886f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d273e8b79cd944ddbd711fc0887d06a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ff20f77b95044f1b73e8290affa20ad",
              "IPY_MODEL_d3054d1047804e0581113ba1f94cb5d9",
              "IPY_MODEL_8b785df9835340028a475e75e65792da"
            ],
            "layout": "IPY_MODEL_199716715ac24d108970f69685aac235"
          }
        },
        "8ff20f77b95044f1b73e8290affa20ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a440ffbbdf0e4765ba9c401269480ca5",
            "placeholder": "",
            "style": "IPY_MODEL_391e392bb4bc4449892fe14af1f35d28",
            "value": "tokenizer_config.json:100%"
          }
        },
        "d3054d1047804e0581113ba1f94cb5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ee5eae3fc349e5bfcfbed47054db46",
            "max": 34173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a30d0e3d051f4d8492a80572c2af245a",
            "value": 34173
          }
        },
        "8b785df9835340028a475e75e65792da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a307dfbe610c44a4a17534fa2aac2eec",
            "placeholder": "",
            "style": "IPY_MODEL_8c1513ccdccd4951af6591587c62a787",
            "value": "34.2k/34.2k[00:00&lt;00:00,3.15MB/s]"
          }
        },
        "199716715ac24d108970f69685aac235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a440ffbbdf0e4765ba9c401269480ca5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "391e392bb4bc4449892fe14af1f35d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8ee5eae3fc349e5bfcfbed47054db46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a30d0e3d051f4d8492a80572c2af245a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a307dfbe610c44a4a17534fa2aac2eec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1513ccdccd4951af6591587c62a787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2d2675a6ae14583a4992f8e1baf6208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e63fdfcd83a74c4fb9ad5bb210d0730a",
              "IPY_MODEL_35c0732a41084e1dbf150f41fa0219cc",
              "IPY_MODEL_9ecff7822b994d71a71d593d9dc00cde"
            ],
            "layout": "IPY_MODEL_c313f8cd52e04a5a98810d543766ab17"
          }
        },
        "e63fdfcd83a74c4fb9ad5bb210d0730a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef7c590a53e74e809cf9dc787c559eed",
            "placeholder": "",
            "style": "IPY_MODEL_7206b40a063b466e940295b737b71308",
            "value": "tokenizer.model:100%"
          }
        },
        "35c0732a41084e1dbf150f41fa0219cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e799b091fa114f56a806c374fc0ed7f4",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cac327851013466d945cfc76e81e7474",
            "value": 4241003
          }
        },
        "9ecff7822b994d71a71d593d9dc00cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de357e6f633d4e8786ef38d9e379e03b",
            "placeholder": "",
            "style": "IPY_MODEL_be6d5ff8b4ac4f489d40bd7f2751d575",
            "value": "4.24M/4.24M[00:00&lt;00:00,9.00MB/s]"
          }
        },
        "c313f8cd52e04a5a98810d543766ab17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef7c590a53e74e809cf9dc787c559eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7206b40a063b466e940295b737b71308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e799b091fa114f56a806c374fc0ed7f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cac327851013466d945cfc76e81e7474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de357e6f633d4e8786ef38d9e379e03b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6d5ff8b4ac4f489d40bd7f2751d575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafcb2a0baac4c44bee93512bb2f7fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43455d9082e14674a552337da30b48a1",
              "IPY_MODEL_8b55f733e19d446a88ae501d81212aef",
              "IPY_MODEL_440c067c133a4223a8143b73b8562359"
            ],
            "layout": "IPY_MODEL_ebf1a83e56e5464291d4a3bb85602fa5"
          }
        },
        "43455d9082e14674a552337da30b48a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5aec701d64bc422f9f0a6a7fdcbb6134",
            "placeholder": "",
            "style": "IPY_MODEL_39df6952cf344db5af55adc26470a10b",
            "value": "tokenizer.json:100%"
          }
        },
        "8b55f733e19d446a88ae501d81212aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9952e2fae8e14de8bb3b8e0abf9ca63f",
            "max": 17518497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9cf7da03d2a4bc3a97b98021c7da8fb",
            "value": 17518497
          }
        },
        "440c067c133a4223a8143b73b8562359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b3e109185ae4f6590dcc2e3db430003",
            "placeholder": "",
            "style": "IPY_MODEL_b818aae861794cc2a635efd2e59955d4",
            "value": "17.5M/17.5M[00:00&lt;00:00,34.7MB/s]"
          }
        },
        "ebf1a83e56e5464291d4a3bb85602fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aec701d64bc422f9f0a6a7fdcbb6134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39df6952cf344db5af55adc26470a10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9952e2fae8e14de8bb3b8e0abf9ca63f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9cf7da03d2a4bc3a97b98021c7da8fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b3e109185ae4f6590dcc2e3db430003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b818aae861794cc2a635efd2e59955d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0081099aad4e4bbabb316260b6f4aa93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0846147fe114458db6d7b88601de0304",
              "IPY_MODEL_a71c17788c4c4e048b3c2448591c6c35",
              "IPY_MODEL_0eaaa5a6854143e4aae1de9c785950c8"
            ],
            "layout": "IPY_MODEL_35dc0034b45a4474a27aefa46cc54ee0"
          }
        },
        "0846147fe114458db6d7b88601de0304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f882311eeead4439b55cbe9b0e3cdb6a",
            "placeholder": "",
            "style": "IPY_MODEL_17db83cef44142efbcee6d8f310312b0",
            "value": "special_tokens_map.json:100%"
          }
        },
        "a71c17788c4c4e048b3c2448591c6c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9f8ceb2c24441da99116e1d1a12cadf",
            "max": 636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41bf276faef54df1aea1e29468f52812",
            "value": 636
          }
        },
        "0eaaa5a6854143e4aae1de9c785950c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50b64e84ac42458ba2de5bbddf76d375",
            "placeholder": "",
            "style": "IPY_MODEL_52de5aa88ffa400eb1085184eccd2722",
            "value": "636/636[00:00&lt;00:00,87.5kB/s]"
          }
        },
        "35dc0034b45a4474a27aefa46cc54ee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f882311eeead4439b55cbe9b0e3cdb6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17db83cef44142efbcee6d8f310312b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9f8ceb2c24441da99116e1d1a12cadf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bf276faef54df1aea1e29468f52812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50b64e84ac42458ba2de5bbddf76d375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52de5aa88ffa400eb1085184eccd2722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}