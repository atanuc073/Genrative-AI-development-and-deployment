{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atanuc073/Genrative-AI-development-and-deployment/blob/main/Viz_LLM_Classification_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuqTfgQU-uC5"
      },
      "source": [
        "# FINETUNING FOR CLASSIFICATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e95t0my_-uC5"
      },
      "source": [
        "### DOWNLOADING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests  # Make sure requests is installed\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path)\n",
        "\n",
        "    ## We have reached here until now ---> we have downloaded the files on our local machine.\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "def download_file(url, destination):\n",
        "    try:\n",
        "        # Send a GET request to download the file, disabling SSL verification\n",
        "        response = requests.get(url, stream=True, verify=False)\n",
        "\n",
        "        # Get the total file size from headers, defaulting to 0 if not present\n",
        "        file_size = int(response.headers.get(\"content-length\", 0))\n",
        "\n",
        "        # Check if file exists and has the same size\n",
        "        if os.path.exists(destination):\n",
        "            file_size_local = os.path.getsize(destination)\n",
        "            if file_size == file_size_local:\n",
        "                print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                return\n",
        "\n",
        "        # Define the block size for reading the file\n",
        "        block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "        # Initialize the progress bar with total file size\n",
        "        progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
        "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "            # Open the destination file in binary write mode\n",
        "            with open(destination, \"wb\") as file:\n",
        "                # Iterate over the file data in chunks\n",
        "                for chunk in response.iter_content(block_size):\n",
        "                    progress_bar.update(len(chunk))  # Update progress bar\n",
        "                    file.write(chunk)  # Write the chunk to the file\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading the file: {e}\")\n",
        "        print(f\"Please check the URL: {url}\")\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "qblWwr5-y0db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8jksjWK-uC5",
        "outputId": "c2f1f00b-b76b-455f-af16-1dee6ccaa2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import ssl\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Create an unverified SSL context\n",
        "    ssl_context = ssl._create_unverified_context()\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn9BqxId-uC5"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "After executing the preceding code, the dataset is saved as a tab-separated text file,\n",
        "SMSSpamCollection.tsv, in the sms_spam_collection folder.\n",
        "\n",
        "We can load it into a pandas\n",
        "DataFrame as follows:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "l2THHqDJ-uC5",
        "outputId": "aa52e2a8-8adc-4dda-b36f-b97b95baa411"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f761a394-0b94-4482-85aa-7e3d6e481082\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f761a394-0b94-4482-85aa-7e3d6e481082')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f761a394-0b94-4482-85aa-7e3d6e481082 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f761a394-0b94-4482-85aa-7e3d6e481082');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-00948bcf-65f2-4306-9251-fe0fda6f7c52\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00948bcf-65f2-4306-9251-fe0fda6f7c52')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-00948bcf-65f2-4306-9251-fe0fda6f7c52 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1c06dff1-0e2d-44d7-af84-808ace6f4a0f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1c06dff1-0e2d-44d7-af84-808ace6f4a0f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh0RUvtO-uC5"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\"\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3uSg2Sh-uC5",
        "outputId": "288c63e4-8bc8-4cbb-d06e-619317debd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"Label\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TAcLFre-uC5"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGYfX4IP-uC5",
        "outputId": "cbc8abec-c4ef-424e-fa10-a2699369be20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def create_balanced_dataset(df):\n",
        "\n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB2fzGW_-uC5"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "After executing the previous code to balance the dataset, we can see that we now have\n",
        "equal amounts of spam and non-spam messages:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuZH6Ayi-uC5"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, we convert the \"string\" class labels \"ham\" and \"spam\" into integer class labels 0 and\n",
        "1, respectively:\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixBCbe9N-uC5"
      },
      "outputs": [],
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLduEtas-uC5"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "This process is similar to converting text into token IDs.\n",
        "\n",
        "However, instead of using the GPT\n",
        "vocabulary, which consists of more than 50,000 words, we are dealing with just two token\n",
        "IDs: 0 and 1.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSUGpWBh-uC5"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "We create a random_split function to split the dataset into three parts: 70% for\n",
        "training, 10% for validation, and 20% for testing.\n",
        "\n",
        "(These ratios are common in machine\n",
        "learning to train, adjust, and evaluate models.)    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAo4jq6J-uC5"
      },
      "outputs": [],
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# Test size is implied to be 0.2 as the remainder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKSt7UCX-uC5",
        "outputId": "4ccdd7fe-726e-4ad7-fe37-b2e36c93fd01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1045\n",
            "149\n",
            "300\n"
          ]
        }
      ],
      "source": [
        "print(len(train_df))\n",
        "print(len(validation_df))\n",
        "print(len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTBLVlNL-uC5"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Additionally, we save the dataset as CSV (comma-separated value) files, which we can\n",
        "reuse later:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx2jTwKt-uC5"
      },
      "outputs": [],
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9voPszL8-uC5"
      },
      "source": [
        "### CREATING DATALOADERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eJ9FoO4-uC5"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Previously, we utilized a sliding window technique to generate uniformly\n",
        "sized text chunks, which were then grouped into batches for more efficient model training.\n",
        "Each chunk functioned as an individual training instance\n",
        "\n",
        "In the case of email spam classification, have two primary options:\n",
        "\n",
        "(1) Truncate all messages to the length of the shortest message in the\n",
        "dataset or batch.\n",
        "\n",
        "(2) Pad all messages to the length of the longest message in the dataset or\n",
        "batch.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKFhF8he-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Option 1 is computationally cheaper, but it may result in significant information loss if\n",
        "shorter messages are much smaller than the average or longest messages, potentially\n",
        "reducing model performance.\n",
        "\n",
        "So, we opt for the second option, which preserves the entire\n",
        "content of all messages.\n",
        "\n",
        "To implement option 2, where all messages are padded to the length of the longest\n",
        "message in the dataset, we add padding tokens to all shorter messages.\n",
        "\n",
        "For this purpose,\n",
        "we use \"<|endoftext|>\" as a padding token, as discussed in chapter 2.\n",
        "\n",
        "    \n",
        "However, instead of appending the string \"<|endoftext|>\" to each of the text messages\n",
        "directly, we can add the token ID corresponding to \"<|endoftext|>\" to the encoded text\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dUWyXus-uC6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "\n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcsZQcOb-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Step 1: Pre-tokenize texts\n",
        "    \n",
        "Step 2: Truncate sequences if they are longer than max_length\n",
        "    \n",
        "Step 3: Pad sequences to the longest sequence\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8sdckcS-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The SpamDataset class loads data from the CSV files we created earlier, tokenizes the text\n",
        "using the GPT-2 tokenizer from tiktoken and allows us to pad or truncate the sequences to\n",
        "a uniform length determined by either the longest sequence or a predefined maximum\n",
        "length.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ4gbEF4-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "This ensures each input tensor is of the same size, which is necessary to create the\n",
        "batches in the training data loader we implement next:\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRt9bqe6_OZz",
        "outputId": "2660e2e9-62da-4889-b8fb-4a15214805e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
            "tiktoken version: 0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken\n",
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOycJzBA-uC6",
        "outputId": "bc7f6d55-7960-4872-fa04-19bb1719c6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F1nckfb-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "The code outputs 120, showing that the longest sequence contains no more than 120\n",
        "tokens, a common length for text messages.\n",
        "                       \n",
        "It's worth noting that the model can handle\n",
        "sequences of up to 1,024 tokens, given its context length limit.\n",
        "\n",
        "If your dataset includes\n",
        "longer texts, you can pass max_length=1024 when creating the training dataset in the\n",
        "preceding code to ensure that the data does not exceed the model's supported input\n",
        "(context) length.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSQWCHh1-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, we pad the validation and test sets to match the length of the longest training\n",
        "sequence.\n",
        "\n",
        "It's important to note that any validation and test set samples exceeding the\n",
        "length of the longest training example are truncated using\n",
        "encoded_text[:self.max_length] in the SpamDataset code we defined earlier.\n",
        "\n",
        "This\n",
        "truncation is optional; you could also set max_length=None for both validation and test\n",
        "sets, provided there are no sequences exceeding 1,024 tokens in these sets\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je0mWbq6-uC6",
        "outputId": "8a771c45-bd83-4412-abb4-4350272ab80b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(test_dataset.max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efhBolHQ-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Using the datasets as inputs, we can instantiate the data loaders similarly to what we did earlier.\n",
        "\n",
        "However, in this case, the targets represent class labels rather than the next\n",
        "tokens in the text.\n",
        "\n",
        "For instance, choosing a batch size of 8, each batch will consist of 8\n",
        "training examples of length 120 and the corresponding class label of each example.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEChGNV_-uC6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtZCDZot-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "To ensure that the data loaders are working and are indeed returning batches of the\n",
        "expected size, we iterate over the training loader and then print the tensor dimensions of\n",
        "the last batch:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd-vOjOm-uC6",
        "outputId": "64a0b00f-164b-4c3c-9ea8-260550f31a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbQ8tolT-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "As we can see, the input batches consist of 8 training examples with 120 tokens each, as\n",
        "expected.\n",
        "\n",
        "The label tensor stores the class labels corresponding to the 8 training examples.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eyxc7JqJ-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Lastly, to get an idea of the dataset size, let's print the total number of batches in each\n",
        "dataset:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIFfuHvK-uC6",
        "outputId": "5c4e80d6-6c91-4d24-d7e8-5136d4a82d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7X6-uv6-uC6"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "This concludes the data preparation. Next, we will prepare the model for\n",
        "finetuning.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHfxiNbH-uC6"
      },
      "source": [
        "## INITIALIZING A MODEL WITH PRETRAINED WEIGHTS\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjMYXOiL-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "In this section, we prepare the model we will use for the classification-finetuning to identify\n",
        "spam messages.\n",
        "\n",
        "We start with initializing the pretrained model we worked with in the\n",
        "previous chapter\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWLhMYMf-uC7"
      },
      "outputs": [],
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA7SRlhe-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, we import the download_and_load_gpt function from the gpt_download3.py file we\n",
        "downloaded earlier.\n",
        "\n",
        "Furthermore, we also reuse the GPTModel class and\n",
        "load_weights_into_gpt function from chapter 5 to load the downloaded weights into the\n",
        "GPT model:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEspazZgCQgc"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t4SCgLzCH6P"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
        "            GELU(), ## Activation\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZmrmgVlCNKK"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        # 2*4*768\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "        # 2*4*768"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvddvvJBCVbh"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELg0NeJ1CqIm"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az-Dt15lCeX5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiA1mj0zC5Ki"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "    ###Input batch:\n",
        " ###tensor([[6109, 3626, 6100,  345],\n",
        "        ##[6109, 1110, 6622,  257]])\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8I6NatR_C_kb"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbRX8uqB-uC7",
        "outputId": "db51c2da-85f7-4843-a742-c6cb1995328f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124M\n"
          ]
        }
      ],
      "source": [
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "print(model_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download3 import download_and_load_gpt2\n",
        "\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWxH6eBzgxUh",
        "outputId": "95b1a0d0-fdf0-4cfb-c534-44c1e7abdaac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 180kiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.18MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 55.2kiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:51<00:00, 9.65MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 9.77MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.57MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.73MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luqtZ6P8ChA2"
      },
      "outputs": [],
      "source": [
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuMPhH4f-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "To ensure that the model was loaded correctly, let's double-check that it generates coherent text\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRHIBz8N-uC7",
        "outputId": "2f84e941-f66f-4f8e-f47b-58207495a253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ],
      "source": [
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_-76Osx-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Now, before we start finetuning the model as a spam classifier, let's see if the model can\n",
        "perhaps already classify spam messages by by prompting it with instructions:\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYFmbnxe-uC7",
        "outputId": "817793b6-1c88-4c26-d51d-9fd04c055927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZbMZn9T-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Based on the output, it's apparent that the model struggles with following instructions.\n",
        "\n",
        "This is anticipated, as it has undergone only pretraining and lacks instruction-finetuning,\n",
        "which we will explore in the upcoming chapter\n",
        "\n",
        "The next section prepares the model for classification-finetuning\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zcxOYj8-uC7"
      },
      "source": [
        "## ADDING A CLASSIFICATION HEAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x35UkwpI-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "In this section, we modify the pretrained large language model to prepare it for\n",
        "classification-finetuning.\n",
        "\n",
        "To do this, we replace the original output layer, which maps the\n",
        "hidden representation to a vocabulary of 50,257, with a smaller output layer that maps to\n",
        "two classes: 0 (\"not spam\") and 1 (\"spam\"),\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADPXyx6a-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "We could technically use a single output node since we are dealing with a binary\n",
        "classification task.\n",
        "\n",
        "However, this would require modifying the loss function.\n",
        "\n",
        "Therefore, we choose a\n",
        "more general approach where the number of output nodes matches the number of\n",
        "classes.\n",
        "\n",
        "For example, for a 3-class problem, such as classifying news articles as\n",
        "\"Technology\", \"Sports\", or \"Politics\", we would use three output nodes, and so forth.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8at8XPkN-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Before we attempt to construct the modified architecture, let's print the model\n",
        "architecture via print(model), which prints the following:\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tMpN6S--uC7",
        "outputId": "d77f595f-21e3-4fd3-cda3-9f102a7c5f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5HURt-L-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Above, we can see the GPT architecture neatly laid out.\n",
        "\n",
        "As\n",
        "discussed earlier, the GPTModel consists of embedding layers followed by 12 identical\n",
        "transformer blocks (only the last block is shown for brevity), followed by a final LayerNorm\n",
        "and the output layer, out_head.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uuC1BUe-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, we replace the out_head with a new output layer, as illustrated in figure 6.9, that\n",
        "we will finetune.    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmmEdbmD-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "To get the model ready for classification-finetuning, we first freeze the model, meaning that\n",
        "we make all layers non-trainable:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_Cp06v5-uC7"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrcwV2rv-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Then, we replace the output layer (model.out_head), which\n",
        "originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary):\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jttLIuGQ-uC7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2npyQRB-uC7"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Note that in the preceding code, we use BASE_CONFIG[\"emb_dim\"], which is equal to 768 in\n",
        "the \"gpt2-small (124M)\" model, to keep the code below more general.\n",
        "\n",
        "This means we\n",
        "can also use the same code to work with the larger GPT-2 model variants.\n",
        "\n",
        "This new model.out_head output layer has its requires_grad attribute set to True by\n",
        "default, which means that it's the only layer in the model that will be updated during\n",
        "training.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7G96C8E-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "This new model.out_head output layer has its requires_grad attribute set to True by\n",
        "default, which means that it's the only layer in the model that will be updated during\n",
        "training.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECNRdaZR-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Additionally, we configure the last transformer block and the final LayerNorm module,\n",
        "which connects this block to the output layer, to be trainable\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5456eB3-uC8"
      },
      "outputs": [],
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3EI8zYU-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Even though we added a new output layer and marked certain layers as trainable or nontrainable, we can still use this model in a similar way to previous chapters.\n",
        "\n",
        "For instance, we\n",
        "can feed it an example text identical to how we have done it in earlier chapters. For\n",
        "example, consider the following example text:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08dvh7wI-uC8",
        "outputId": "4fa1b3f6-ef7a-4dbc-c525-52bdf33576c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjeN5nVy-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Then, we can pass the encoded token IDs to the model as usual:\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENljMfl9-uC8",
        "outputId": "3319bb22-a660-46df-d00f-96a08b46ff84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[-1.5854,  0.9904],\n",
            "         [-3.7235,  7.4548],\n",
            "         [-2.2661,  6.6049],\n",
            "         [-3.5983,  3.9902]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie0GXz6u-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "In earlier chapters, a similar input would have produced an output tensor of [1, 4, 50257],\n",
        "where 50,257 represents the vocabulary size.\n",
        "\n",
        "As in previous chapters, the number of\n",
        "output rows corresponds to the number of input tokens (in this case, 4).\n",
        "\n",
        "However, each\n",
        "output's embedding dimension (the number of columns) is now reduced to 2 instead of\n",
        "50,257 since we replaced the output layer of the model.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0itF9srZ-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Remember that we are interested in finetuning this model so that it returns a class label\n",
        "that indicates whether a model input is spam or not spam.\n",
        "\n",
        "To achieve this, we don't need to\n",
        "finetune all 4 output rows but can focus on a single output token.\n",
        "\n",
        "In particular, we will\n",
        "focus on the last row corresponding to the last output token\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoJMJrlB-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "To extract the last output token, illustrated in figure 6.11, from the output tensor, we\n",
        "use the following code:    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fod2-XqV-uC8",
        "outputId": "8ab5e332-c9bd-4659-c4e7-ffddc9903b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81lBw3NR-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Having modified the model, the next section will detail the process of transforming the\n",
        "last token into class label predictions and calculate the model's initial prediction accuracy.\n",
        "\n",
        "Following this, we will finetune the model for the spam classification task in the subsequent\n",
        "section.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RN2T0XN-uC8"
      },
      "source": [
        "## CALCULATING THE CLASSIFICATION LOSS AND ACCURACY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbIeye5W-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "So far in this chapter, we have prepared the dataset, loaded a pretrained model, and\n",
        "modified it for classification-finetuning.\n",
        "           \n",
        "Before we proceed with the finetuning itself, only\n",
        "one small part remains: implementing the model evaluation functions used during\n",
        "finetuning,  \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L8EIc9Z-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Before implementing the evaluation utilities, let's briefly discuss how we convert the model\n",
        "outputs into class label predictions.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhK4NCMZ-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "In the previous chapter, we computed the token ID of the next token generated by the\n",
        "LLM by converting the 50,257 outputs into probabilities via the softmax function and then\n",
        "returning the position of the highest probability via the argmax function.\n",
        "\n",
        "In this chapter, we\n",
        "take the same approach to calculate whether the model outputs a \"spam\" or \"not spam\"\n",
        "prediction for a given input, with the only difference being that we\n",
        "work with 2-dimensional instead of 50,257-dimensional outputs.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbtMe9qZ-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's consider the last token output from\n",
        "the previous section:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3BdIwL2-uC8",
        "outputId": "0b2299ac-6139-44c1-8fb4-a22ed459ee08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_WaFghb-uC8"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "We can obtain the class label via the following code:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZbrjAOE-uC9",
        "outputId": "57f3c68e-b0fc-4241-c57b-44c3017cf645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5.0598e-04, 9.9949e-01]])\n",
            "Class label: 1\n"
          ]
        }
      ],
      "source": [
        "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
        "print(probas)\n",
        "label = torch.argmax(probas)\n",
        "print(\"Class label:\", label.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoowOxvV-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "In this case, the code returns 1, meaning the model predicts that the input text is \"spam.\"\n",
        "\n",
        "Using the softmax function here is optional because the largest outputs directly correspond\n",
        "to the highest probability scores.\n",
        "\n",
        "Hence, we can simplify the\n",
        "code as follows, without using softmax:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYu8UU8Q-uC9",
        "outputId": "b22c5364-f034-441c-8cf4-ba255eeb20a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ],
      "source": [
        "logits = outputs[:, -1, :]\n",
        "label = torch.argmax(logits)\n",
        "print(\"Class label:\", label.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amB1rjd7-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "This concept can be used to compute the so-called classification accuracy, which measures\n",
        "the percentage of correct predictions across a dataset.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx-Vo_vc-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "To determine the classification accuracy, we apply the argmax-based prediction code to\n",
        "all examples in the dataset and calculate the proportion of correct predictions by defining a\n",
        "calc_accuracy_loader function:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abFZdTkl-uC9"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyKwcVYH-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Let's use the function to determine the classification accuracies across various datasets\n",
        "estimated from 10 batches for efficiency:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yV56jXK-uC9",
        "outputId": "542b588e-bbac-4795-8552-c5ba8efe4a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 45.00%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
        "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#print(f\"Running on {device} device.\")\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93rpTu1K-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "As we can see, the prediction accuracies are near a random prediction, which would be\n",
        "50% in this case.\n",
        "\n",
        "To improve the prediction accuracies, we need to finetune the model.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49jQ6RT5-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Classification accuracy is not a differentiable function, so we use cross entropy\n",
        "loss as a proxy to maximize accuracy.\n",
        "\n",
        "This is the same cross entropy loss discussed earlier.\n",
        "\n",
        "Accordingly, the calc_loss_batch function remains the same as in earlier, with one\n",
        "adjustment: we focus on optimizing only the last token, model(input_batch)[:, -1, :],\n",
        "rather than all tokens, model(input_batch):\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-paBtz8Y-uC9"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpYZHlLO-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "We use the calc_loss_batch function to compute the loss for a single batch obtained from\n",
        "the previously defined data loaders. To calculate the loss for all batches in a data loader, we\n",
        "define the calc_loss_loader function\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G46k__Pq-uC9"
      },
      "outputs": [],
      "source": [
        "# Same as in chapter 5\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2wLZ4um-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Similar to calculating the training accuracy, we now compute the initial loss for each\n",
        "data set:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrRjHI24-uC9",
        "outputId": "c208a97a-f3e8-4dac-9efd-a975b62fe26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.453\n",
            "Validation loss: 2.583\n",
            "Test loss: 2.322\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB-0L2po-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "In the next section, we will implement a training function to finetune the model, which\n",
        "means adjusting the model to minimize the training set loss.\n",
        "\n",
        "Minimizing the training set\n",
        "loss will help increase the classification accuracy, our overall goal\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEYs5CMV-uC9"
      },
      "source": [
        "## FINETUNING THE MODEL ON SUPERVISED DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXiJ3C3Q-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "In this section, we define and use the training function to finetune the pretrained LLM and\n",
        "improve its spam classification accuracy.\n",
        "    \n",
        "The training loop is the\n",
        "same overall training loop we used earlier, with the only difference being that we\n",
        "calculate the classification accuracy instead of generating a sample text for evaluating the\n",
        "model.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOCv1b2s-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "The training function also closely mirrors\n",
        "the train_model_simple function used for pretraining the model earlier.\n",
        "                                    \n",
        "The only two distinctions are that we now track the number of training examples seen\n",
        "(examples_seen) instead of the number of tokens, and we calculate the accuracy after each\n",
        "epoch instead of printing a sample text:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8NYt04e-uC9"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Step 1: Set model to training mode\n",
        "\n",
        "Step 2: Reset loss gradients from previous batch iteration\n",
        "\n",
        "Step 3: Calculate loss gradients\n",
        "\n",
        "Step 4: Update model weights using loss gradients\n",
        "\n",
        "Step 5: New: track examples instead of tokens\n",
        "\n",
        "Step 6: Optional evaluation step\n",
        "\n",
        "Step 7: Calculate accuracy after each epoch\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NovBdEYI-uC-"
      },
      "outputs": [],
      "source": [
        "# Overall the same as `train_model_simple` in chapter 5\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # Initialize lists to track losses and examples seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            ## 130 batches: training, eval_Freq = 50 --> after 50 batches are processed in each epoch, we print train loss and val loss\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQTnLR81-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "The evaluate_model function used in the train_classifier_simple is the same as the one we used earlier.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DesMsOy-uC-"
      },
      "outputs": [],
      "source": [
        "# Same as chapter 5\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoR-LoGZ-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, we initialize the optimizer, set the number of training epochs, and initiate the training\n",
        "using the train_classifier_simple function.\n",
        "\n",
        "We will discuss the choice of the the number\n",
        "of training epochs after we evaluated the results.\n",
        "\n",
        "The training takes about 6 minutes on an\n",
        "M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0M8hsV_-uC-",
        "outputId": "ff8dd8b9-f901-4912-904c-cfaa3cbe988e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
            "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
            "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
            "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
            "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
            "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
            "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
            "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Training completed in 0.65 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 3\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jLSTaEA-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "We then use matplotlib to plot the loss function for the training and\n",
        "validation set:\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndavlijh-uC-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_5fkpI4-uC-",
        "outputId": "9fd4e0fa-f731-4d32-c90a-c2f614df7c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVi6js19-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "As we can see based on the sharp downward slope, the model is learning well\n",
        "from the training data, and there is little to no indication of overfitting; that is, there is no\n",
        "noticeable gap between the training and validation set losses).\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzUGlIcv-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Using the same plot_values function, let's now also plot the classification accuracies:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODE5DHFz-uC-",
        "outputId": "e24b7973-61e8-40db-d829-cb7ce1b0a007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xzV9SG_-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Based on the accuracy plot, the model achieves a relatively high training and\n",
        "validation accuracy after epochs 4 and 5.\n",
        "    \n",
        "However, it's important to note that we previously set eval_iter=5 when using the\n",
        "train_classifier_simple function, which means our estimations of training and\n",
        "validation performance were based on only 5 batches for efficiency during training.\n",
        "\n",
        "Now, we will calculate the performance metrics for the training, validation, and test sets\n",
        "across the entire dataset by running the following code, this time without defining the\n",
        "eval_iter value:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZpokSXE-uC-",
        "outputId": "6ea0e638-a2f8-4860-b3e7-a8a8a6f79711",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 87.21%\n",
            "Validation accuracy: 91.28%\n",
            "Test accuracy: 88.00%\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz1WuUJw-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The training and test set performances are almost identical.\n",
        "\n",
        "A slight discrepancy between the training and test set accuracies suggests minimal\n",
        "overfitting of the training data.\n",
        "\n",
        "Typically, the validation set accuracy is somewhat higher\n",
        "than the test set accuracy because the model development often involves tuning\n",
        "hyperparameters to perform well on the validation set, which might not generalize as\n",
        "effectively to the test set.\n",
        "\n",
        "This situation is common, but the gap could potentially be minimized by adjusting the\n",
        "model's settings, such as increasing the dropout rate (drop_rate) or the weight_decay\n",
        "parameter in the optimizer configuration.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E45F7dyV-uC-"
      },
      "source": [
        "## USING THE LLM AS A SPAM CLASSIFIER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NfgLsJd-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "After finetuning and evaluating the model in the previous sections, we are now in the final\n",
        "stage of this chapter:  using the model to classify spam\n",
        "messages.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwLuVYso-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Finally, let's use the finetuned GPT-based spam classification model.\n",
        "\n",
        "The following\n",
        "classify_review function follows data preprocessing steps similar to those we used in the\n",
        "SpamDataset implemented earlier in this chapter.\n",
        "\n",
        "And then, after processing text into token\n",
        "IDs, the function uses the model to predict an integer class label, similar to what we have\n",
        "implemented earlier, and then returns the corresponding class name:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfHSWvo7-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Step 1: Prepare inputs to the model\n",
        "\n",
        "Step 2: Truncate sequences if they too long\n",
        "    \n",
        "Step 3: Pad sequences to the longest sequence\n",
        "\n",
        "Step 4: Add batch dimension\n",
        "\n",
        "Step 5: Model inference without gradient tracking\n",
        "    \n",
        "Step 6: Logits of the last output token\n",
        "\n",
        "Step 7: Return the classified result\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYV1tIon-uC-"
      },
      "outputs": [],
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
        "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"spam\" if predicted_label == 1 else \"not spam\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWzI5d2j-uC-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's try this classify_review function on an example text:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ID4Lnbc-uC_",
        "outputId": "fec51c77-8063-49bf-93a1-58b1599e1050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ],
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6AZgPbW-uC_"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "The resulting model correctly predicts \"spam\".\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elN5aYHw-uC_",
        "outputId": "189a34ef-fb8b-4ac4-e2a1-1e8b09719de6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCtZCX_l-uC_"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Also, here, the model makes a correct prediction and returns a \"not spam\" label.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mryo6b--uC_"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Finally, let's save the model in case we want to reuse the model later without having to\n",
        "train it again using the torch.save method\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhE9u2Au-uC_"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIcyvkUW-uC_"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Once saved, the model can be loaded as follows:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeWb-hQw-uC_",
        "outputId": "7cb39ecd-0cc2-4d88-e1e7-d10efc7fd1d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "model_state_dict = torch.load(\"review_classifier.pth\")\n",
        "model.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOjaz8qk-uDG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}